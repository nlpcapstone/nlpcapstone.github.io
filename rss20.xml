<?xml version="1.0"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">

<channel>
	<title>NLP Capstone Spring 2018</title>
	<link>https://nlpcapstone.github.io/</link>
	<language>en</language>
	<description>NLP Capstone Spring 2018 - https://nlpcapstone.github.io/</description>
	<atom:link rel="self" href="https://nlpcapstone.github.io/rss20.xml" type="application/rss+xml"/>

<item>
	<title>Rajas Agashe &lt;br/&gt; Team Han Flying Solo: Blog Post 1</title>
	<guid isPermaLink="false">tag:blogger.com,1999:blog-5600014144802012716.post-6768023392170538237</guid>
	<link>https://nlpcapstonesemparse.blogspot.com/2018/03/blog-post-1.html</link>
	<description>&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;font-family: arial;&quot;&gt;&lt;span style=&quot;font-size: 14.6667px; white-space: pre;&quot;&gt;I am interested in working in the code generation/semantic parsing space on the research track. My code &lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-family: arial;&quot;&gt;&lt;span style=&quot;font-size: 14.6667px; white-space: pre;&quot;&gt;will be in various branches of my fork of allennlp (https://github.com/rajasagashe/allennlp). I will keep you&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-family: arial;&quot;&gt;&lt;span style=&quot;font-size: 14.6667px; white-space: pre;&quot;&gt; updated on which branch/commits I worked on during each blog post. Also note that project idea 1 has &lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span style=&quot;font-family: arial;&quot;&gt;&lt;span style=&quot;font-size: 14.6667px; white-space: pre;&quot;&gt;the most detail since I have picked it as my project!&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;h2 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 18pt;&quot;&gt;&lt;span&gt;Project Idea 1&lt;/span&gt;&lt;/h2&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Minimum Viable Plan:&lt;/span&gt;&lt;span&gt; Implement the model in the recent UW paper which introduces the task of &lt;/span&gt;&lt;br /&gt;&lt;span&gt;generating the code for a java function from a natural language description. To further aid code &lt;/span&gt;&lt;br /&gt;&lt;span&gt;generation, the class in which the generated function is to reside is provided, i.e. the class variables &lt;/span&gt;&lt;br /&gt;&lt;span&gt;and methods. Thus the encoder encodes the class as well as the utterance and the decoder uses a &lt;/span&gt;&lt;br /&gt;&lt;span&gt;two step attention mechanism and decodes through the java grammar production rules. &lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Stretch Goals:&lt;/span&gt;&lt;span&gt; Reproduce the state of the art results in the paper. I’m putting this in the stretch goals &lt;/span&gt;&lt;br /&gt;&lt;span&gt;since successfully implementing a neural semantic parser with type constraints is pretty challenging. &lt;/span&gt;&lt;br /&gt;&lt;span&gt;In addition, I hope to experiment with other improvements like encoding the entire class method body&lt;/span&gt;&lt;br /&gt;&lt;span&gt; which wasn’t done.&lt;/span&gt;&lt;/div&gt;&lt;h2 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 18pt;&quot;&gt;&lt;span&gt;Project Idea 2&lt;/span&gt;&lt;/h2&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Minimum Viable Plan: &lt;/span&gt;&lt;span&gt;Implement this paper: &lt;/span&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.01696.pdf&quot; style=&quot;text-decoration: none;&quot;&gt;&lt;span&gt;https://arxiv.org/pdf/1704.01696.pdf&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. The model is &lt;/span&gt;&lt;br /&gt;&lt;span&gt;similar to that of the previous idea, but the datasets are for python and ifttt instead.&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Stretch Goals: &lt;/span&gt;&lt;span&gt;Improve the paper’s result.&lt;/span&gt;&lt;/div&gt;&lt;h2 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 18pt;&quot;&gt;&lt;span&gt;Project Idea 3&lt;/span&gt;&lt;/h2&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Minimum Viable Plan: &lt;/span&gt;&lt;span&gt;Perform transfer learning across several code generation tasks by using the &lt;/span&gt;&lt;br /&gt;&lt;span&gt;same encoder for them all. This technique would be similar to what was used in the Cove paper &lt;/span&gt;&lt;br /&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.00107.pdf&quot; style=&quot;text-decoration: none;&quot;&gt;&lt;span&gt;https://arxiv.org/pdf/1708.00107.pdf&lt;/span&gt;&lt;/a&gt;&lt;span&gt;. &lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Stretch Goals: &lt;/span&gt;&lt;span&gt;Improve the individual paper results with this technique.&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;</description>
	<pubDate>Fri, 30 Mar 2018 22:41:00 +0000</pubDate>
	<author>noreply@blogger.com (nlpcapstone)</author>
</item>

</channel>
</rss>
