<?xml version="1.0"?>
<rdf:RDF
	xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:foaf="http://xmlns.com/foaf/0.1/"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns="http://purl.org/rss/1.0/"
>
<channel rdf:about="https://nlpcapstone.github.io/">
	<title>NLP Capstone Spring 2018</title>
	<link>https://nlpcapstone.github.io/</link>
	<description>NLP Capstone Spring 2018 - https://nlpcapstone.github.io/</description>
	<atom:link rel="self" href="https://nlpcapstone.github.io/rss10.xml" type="application/rss+xml"/>

	<items>
		<rdf:Seq>
			<rdf:li rdf:resource="https://medium.com/p/b7c31ac45ecc" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-7864337718441481784" />
			<rdf:li rdf:resource="https://medium.com/p/33072535817f" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-3973266691169482239" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-6866691098285474093" />
			<rdf:li rdf:resource="https://medium.com/p/a2d837ecf66b" />
			<rdf:li rdf:resource="https://medium.com/p/6f773ae418d0" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-3361785683406757277" />
			<rdf:li rdf:resource="https://medium.com/p/306dca636d3a" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-597849658553454254" />
			<rdf:li rdf:resource="https://medium.com/p/be87c31976b7" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-3753031463594823927.post-8569998071322028844" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-1250926726356516395" />
			<rdf:li rdf:resource="https://medium.com/p/7d8e9ec1a8e3" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-3753031463594823927.post-4531878816260312232" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-5878905571398539101" />
			<rdf:li rdf:resource="https://medium.com/p/96fb908765f5" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-3753031463594823927.post-2253300890173394060" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-34377626932024049" />
			<rdf:li rdf:resource="https://medium.com/p/ee873b6885d5" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-9203775015655831448.post-3003438141513431489" />
			<rdf:li rdf:resource="tag:blogger.com,1999:blog-3753031463594823927.post-6307882466820480344" />
		</rdf:Seq>
	</items>
</channel>

<item rdf:about="https://medium.com/p/b7c31ac45ecc">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 09: Any Summary</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-09-any-summary-b7c31ac45ecc?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;previous posts: &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;&lt;em&gt;01&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;&lt;em&gt;02&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3&quot;&gt;&lt;em&gt;03&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-04-first-steps-be87c31976b7&quot;&gt;&lt;em&gt;04&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-05-experimenting-306dca636d3a&quot;&gt;&lt;em&gt;05&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-06-uncertainty-6f773ae418d0&quot;&gt;&lt;em&gt;06&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-07-formalizing-a2d837ecf66b&quot;&gt;&lt;em&gt;07&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-08-human-summaries-33072535817f&quot;&gt;&lt;em&gt;08&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;In my last post, I stated a main goal of mine was to visualization &lt;strong&gt;human summaries&lt;/strong&gt;. After talking with Prof. Jeff Heer this past week, I’ve developed a more concrete goal for this segment of my project.&lt;/p&gt;&lt;p&gt;If we are able to develop a method for approximating human ‘attention’ between source and summary, we can use it in the following ways.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Evaluation tool.&lt;/strong&gt; Current evaluation requires reading article, summary, and thinking critically to map between the two in order to determine whether or not the summary is ‘good’.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enable cross-model comparison and analysis.&lt;/strong&gt; How do different models produce summaries for the same article? Automatic measures, such as Rouge and Meteor, are generally poor indicators of proper quality. Currently, one may read summaries and source text and attempt to qualify proper coverage of key ideas. By introducing a visualization that can be generated from &lt;strong&gt;any&lt;/strong&gt; source-summary pair, we can enable more principled analysis.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enable model to human comparison and analysis.&lt;/strong&gt; This I discussed in the previous post. What do human summaries have that our models are missing? Missing coverage? Missing entities? This visualization tool could answer these questions.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;In general, this tool would allow researchers to gain insights about both human and machine summaries.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;With this in mind, I’ll go into the approaches I’ve been experimenting with in the past week.&lt;/p&gt;&lt;h4&gt;Hierarchical Similarity&lt;/h4&gt;&lt;p&gt;Last week, I attempted token-on-token similarity. The results can be seen the gif below. The weight between input and output token &lt;em&gt;x &lt;/em&gt;and &lt;em&gt;y&lt;/em&gt;, respectively, can be described as so:&lt;/p&gt;&lt;p&gt;&lt;em&gt;a(x, y) = similarity(x, y)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Where similarity is calculated using a standard word embedding API (in this case, &lt;a href=&quot;https://spacy.io/&quot;&gt;spaCy&lt;/a&gt;). The issue with this approach was that context is lost, and so a word will often attend to nearly the entire document with no regard to the ideas coming out of each portion (in summaries, we expect a sentence or phrase to summarize a specific part or few parts of the original document).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*-ganHe0RsisBYzaPKOuHhA.gif&quot; /&gt;Token-on-token similarity pays no heed to context — problematic.&lt;/figure&gt;&lt;p&gt;In attempt to remedy this, I added a factor to each weight that represents the similarity of the tokens’ respective sentences. That is, the weight of a given &lt;em&gt;x, y&lt;/em&gt; pair is determined by the similarity of the sentence of &lt;em&gt;x &lt;/em&gt;and the sentence of &lt;em&gt;y&lt;/em&gt;, multiplied by the similarity of the tokens themselves. To both normalize weights (over output token) and exaggerate salient pairs, I also add a soft-max transformation for each similarity score. The equation below describes this formula.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*WE0z9rPYF_Nb_X4Y.&quot; /&gt;&lt;/figure&gt;&lt;p&gt;The &lt;em&gt;theta&lt;/em&gt; terms here are important in properly exaggerating salient pairs, and so require some tuning.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*QJFNJ0ty3NimB1nBAnTdXg.gif&quot; /&gt;Hierarchical Similarity shows some promise, but has a few issues.&lt;/figure&gt;&lt;p&gt;This approach shows some promise. Context is taken into account, at least at a sentence-by-sentence level. However, there are a few shortcomings that become apparent with more abstractive summaries. In particular:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Context is better but far from perfect.&lt;/strong&gt; Sometimes ideas span multiple sentences, difficult to model. Additionally, repeating words in a sentence get equal ‘attention’ even though one may make more sense from a token-by-token generation standpoint.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I’ll be exploring this approach further in the next week, but I have concerns about its ability to generalize well, per issues described above.&lt;/p&gt;&lt;h4&gt;Hidden Markov Model&lt;/h4&gt;&lt;p&gt;At a high level, we can imagine ‘attention’ as the words and phrases from the source text to that one would draw from to write a portion of a summary. This makes sense: we tend to focus on specific areas of a document at a time when writing summaries. Breaking this into token-by-token time-steps, summary token is &lt;strong&gt;conditioned&lt;/strong&gt; on the ‘attention’ vector for that time-step.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/151/1*6wNP-KSn13tGSSwDjmDXxw.png&quot; /&gt;Summary tokens are conditioned on attention vectors over the source text.&lt;/figure&gt;&lt;p&gt;Further, we can reason that attention vectors change from time-step to time-step, dependent on the previous attention vector.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/361/1*krjZPlauErnawaKymE5LAA.png&quot; /&gt;Attention vectors are conditioned on each other.&lt;/figure&gt;&lt;p&gt;This of course is an simplification — the way our minds work is likely far more complex — but it allows us to model the ‘attention’ between source and summary as a Hidden Markov Model (HMM).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/611/1*3wfXRV8pMJZQ74Ux1OGjDA.png&quot; /&gt;Source to summary modeled as a Hidden Markov Model.&lt;/figure&gt;&lt;p&gt;We can then use this model to predict attention vectors at each time-step (e.g. Viterbi, Forward-Backward). This is similar to how HMMs are used to predict part-of-speech tags (where POS tags are conditioned on each other and tokens are conditioned on those tags). Emissions (the edge weight going from distribution to summary token) can be defined by token similarity, but there are still a challenges here.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;How to define transition probabilities?&lt;/li&gt;&lt;li&gt;Treat attention states as distributions or single tokens (e.g. argmax in vector)?&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I’ll need to consider this approach further to see if I can work out these kinks.&lt;/p&gt;&lt;h4&gt;POS Tags&lt;/h4&gt;&lt;p&gt;I’ve also been slowly improving the visualization tool itself. I’ll briefly describe my progress on this front.&lt;/p&gt;&lt;p&gt;Using &lt;a href=&quot;https://www.nltk.org/&quot;&gt;NLTK&lt;/a&gt;, I was able to part-of-speech tag machine-generated summaries. At the top right of the visualization, users are presented a panel of the POS Tags used by the &lt;a href=&quot;https://catalog.ldc.upenn.edu/ldc99t42&quot;&gt;Penn Tree Bank&lt;/a&gt;, which NLTK sources from. Non-present tags are greyed-out.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1000/1*i87AaOJBtCzk4h_G5b5z9A.gif&quot; /&gt;Users can highlight tokens to view the corresponding tag, or mouse over tags to highlight all corresponding tokens.&lt;/figure&gt;&lt;p&gt;This should allow more in-depth analysis of the attention vectors produced by the machine. Eventually I’d like to work towards highlighting named entities in the source / summary to allow users to identify present / missing ideas centered on important entities.&lt;/p&gt;&lt;h4&gt;Upcoming Work&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;Continue working on visualizing source-summary alignment.&lt;/li&gt;&lt;li&gt;Continue improving visualization.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I have lots, lots, lots to do. Until next time!&lt;/p&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b7c31ac45ecc&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-05-23T06:43:01+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-7864337718441481784">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #9 Milestone: Advanced model attempt #2 (continued)</title>
	<link>https://teamoverfit.blogspot.com/2018/05/9-milestone-advanced-model-attempt-2.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #9: 05/22/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;&lt;b&gt;What We Did:&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Use news data and write preprocessor&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;The drawback of News Tweets&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span id=&quot;docs-internal-guid-883230d4-8b20-8c22-2807-843c883c978c&quot;&gt;&lt;span&gt;Too short for each tweet and not informative enough for the model to learn from it.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span id=&quot;docs-internal-guid-af2383c6-8b20-b2a3-a62a-455584d56812&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Some news tweets don’t summarize well for the real content and cause misleading predictions.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-e02be321-8b21-0416-2fa0-ef6480c92d92&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;The sources of such news tweets are mostly unauthorized.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-e9f853fe-8b21-3a41-e15b-561e8b9a7498&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Therefore, we decided to move on and explore new news sources which are authorized as our input.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-00d89dbe-8b21-6184-8856-59ddaaef7254&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;We used the financial news published everyday and crawl the content directly, instead of using the titles. This will increase the input size for each news. However, it helps the model to gain more information from each single news.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-a49c91be-8b21-8bf2-9b24-72087904ee5d&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;The link to the source we use: &lt;/span&gt;&lt;span style=&quot;color: #1155cc; vertical-align: baseline;&quot;&gt;&lt;a href=&quot;https://intrinio.com/tutorial/file_download#News&quot;&gt;https://intrinio.com/tutorial/file_download#News&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Model Optimization&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-d56ee8ab-8b21-eec9-1c8a-26602af6d372&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Add learning rate decay to our training&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;This helps the model to converge smoothly at the end of training&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-cd723ea4-8b22-d2e3-4c18-27df8c103e58&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Investigate the correlation between sentiment analysis of Tweets and stock price movement&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;We categorize the attitudes in each tweets and news, which increase our feature size&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-ac7fa55e-8b23-3684-d1f2-4eda487b4e92&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Also, we compare the overall attitudes of all tweets and news each day with the prediction made by the model and the real stock price.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-56177478-8b23-82ae-6d6a-d780f77fdf2a&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Visualize and investigate our prediction/training to have better understanding of our model&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Find out the top k words that have most weight for a given day&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Most of them do not seem to relate to stock price movement&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-51b8e57b-8b23-fc01-5457-d60abea87f96&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Compare the prediction/target graph for each epochs to see if the predictions are improving/converging&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Graphs:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;a href=&quot;https://2.bp.blogspot.com/-cvX-eD-CWqI/WwTph39sPdI/AAAAAAAAAAY/p-YRfgomFu0oyiXeSsMXTRAhNRQ4FbPGgCEwYBhgL/s1600/final.png&quot; style=&quot;clear: left; margin-bottom: 1em; margin-right: 1em;&quot;&gt;&lt;img border=&quot;0&quot; height=&quot;133&quot; src=&quot;https://2.bp.blogspot.com/-cvX-eD-CWqI/WwTph39sPdI/AAAAAAAAAAY/p-YRfgomFu0oyiXeSsMXTRAhNRQ4FbPGgCEwYBhgL/s640/final.png&quot; width=&quot;640&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;div&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;Possible Next steps&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Predict more stock prices in the further future rather than just the next day.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Implement an application to help optimize investment strategy&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;ul&gt;&lt;ul&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-05-23T04:11:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/33072535817f">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 08: Human Summaries</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-08-human-summaries-33072535817f?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;previous posts: &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;&lt;em&gt;01&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;&lt;em&gt;02&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3&quot;&gt;&lt;em&gt;03&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-04-first-steps-be87c31976b7&quot;&gt;&lt;em&gt;04&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-05-experimenting-306dca636d3a&quot;&gt;&lt;em&gt;05&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-06-uncertainty-6f773ae418d0&quot;&gt;&lt;em&gt;06&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-07-formalizing-a2d837ecf66b&quot;&gt;&lt;em&gt;07&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;I’ll keep this blogpost short — my current undertakings are in-progress and it might be a week or more before they are realized. To preface:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Visualizing human summaries&lt;/li&gt;&lt;li&gt;Improving the visualization.&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Visualizing Human Summaries&lt;/h3&gt;&lt;p&gt;When I was presenting my project update last week, Prof. Choi asked a very interesting question. What if we could use this visualization tool to not only understand how the model is generating summaries, but also how human summaries are produced and how the two compare?&lt;/p&gt;&lt;p&gt;I’ll briefly explain the thought behind this.&lt;/p&gt;&lt;p&gt;Visualizations provide a mapping from raw data (in this case, attention weights and input / output tokens) to visual encodings. These visual encodings are valuable in that they allow us as humans to perceive the data in a meaningful way. For example, the attention visualizer I am working on allows us to identify overall patterns in the attention of the model.&lt;/p&gt;&lt;p&gt;How do we interpret human written summaries, i.e. their relation to the source text? Perhaps we scan the document and attempt to match paragraphs or sentences to sentences in the summary. This can be compared to the ‘attention’ our minds use to generate the summary. If we can visualize this mapping, perhaps in a more refined and detailed manner (i.e. token by token) then we should be able to compare the human summaries with the machine generated summaries, right? And then one may be able to identify what the human summaries have that the machine summaries do not, or visa versa. The hope is that if we can enable this kind of comparison, researchers may be better equipped to improve their models by using these insights.&lt;/p&gt;&lt;p&gt;So far, I’ve experimented with two methods for generating this ‘attention’ from human summary to source text.&lt;/p&gt;&lt;h4&gt;Word Similarity&lt;/h4&gt;&lt;p&gt;The first approach that sprung to mind was to use word similarity as a proxy for ‘attention’. To do this, I used &lt;a href=&quot;https://nlp.stanford.edu/projects/glove/&quot;&gt;pre-trained GloVe embeddings&lt;/a&gt; and the &lt;a href=&quot;https://radimrehurek.com/gensim/&quot;&gt;Gensim API&lt;/a&gt; to calculate word similarities between each input token / output token pair. &lt;a href=&quot;https://spacy.io/&quot;&gt;SpaCy&lt;/a&gt; was used to tokenize the sequences. The result is a matrix of weights, similar to attention distribution, albeit not normalized per output token (with attention, for a given output token the aggregate over all input tokens is 1). As the example below shows, this method falls flat, as output tokens are matched to input tokens regardless of context. This means it makes little sense to compare these weights to attention.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*D6pMsnZjlNiz1XJyN5xcBQ.png&quot; /&gt;The word ‘the’ is matched with nearly every token in the input sequence, likely a result of its extreme commonness and proximity to most words in embedding space.&lt;/figure&gt;&lt;h4&gt;Summarization Model&lt;/h4&gt;&lt;p&gt;The second method I considered was one suggested by Ari. Here, we use the same model used to generate the machine summaries. The difference is that at each decoder time-step, instead of feeding in the previous &lt;strong&gt;predicted&lt;/strong&gt; token, we feed in the previous &lt;strong&gt;actual&lt;/strong&gt; token. This means that instead of having a decoding pipeline that looks like this:&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*N-til0kZzQeAVI3zkoDKVg.jpeg&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Where y-hats represent predicted output tokens, we have one that looks like this:&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*H7nMlelojnzNkfthS2ljAg.jpeg&quot; /&gt;&lt;/figure&gt;&lt;p&gt;Where y (no hat) represents true output token (the token from the human summary). This is a process similar to the one taken during training of generative encoder-decoder models.&lt;/p&gt;&lt;p&gt;By grabbing attention distributions just as we had with the machine summaries, we hope to get an approximation of the attention distributions for the human summaries — we are essentially feeding the model the answer. However, there is a catch, and an important one. Because attention weights are used to create a context vector that is then fed into the &lt;strong&gt;next&lt;/strong&gt; decoder unit to predict the &lt;strong&gt;next &lt;/strong&gt;word, we run into an issue when the next word is predicted incorrectly. Turns out, this happens often under the model being used (from &lt;a href=&quot;https://github.com/abisee/pointer-generator&quot;&gt;See et al.&lt;/a&gt;). This actually makes sense, as the model has been shown to produce largely &lt;strong&gt;extractive &lt;/strong&gt;summaries, and so one would expect the model to, at each time-step, attempt to produce the next word in the source text that follows the word fed to it. With &lt;strong&gt;abstractive&lt;/strong&gt; summaries, this is not often the optimal choice. This results in attention weights that make little sense, as seen below.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*c5KuVp0qzjkcQxNAJSfYLw.png&quot; /&gt;According to this, ‘manager’ was the focal point of attention when producing the word ‘were’. It would seem that the model intended to predict ‘manager’, and so when we map this attention weight to the human token, we run into an issue.&lt;/figure&gt;&lt;p&gt;Here’s the problem. The model is trained to use attention weights to &lt;strong&gt;generate &lt;/strong&gt;an output token. What we want is the opposite. We want the attention &lt;strong&gt;given&lt;/strong&gt; an output token — use the output token to generate the attention weights. This poses a significant challenge.&lt;/p&gt;&lt;h4&gt;So How Else?&lt;/h4&gt;&lt;p&gt;So neither of these methods seem to produce anything meaningful. I’m not ready to give up though — this is an intriguing problem. In the next week I’ll be brainstorming other methods. One that might have some traction is to use a few heuristics to approximate ‘attention’ using word similarities in conjunction with context. For example, by imposing a penalty on the weight if the context of the output token is dissimilar to the word ‘attended’ to in the source text. Much more work to be done here.&lt;/p&gt;&lt;h3&gt;Improving the visualization&lt;/h3&gt;&lt;p&gt;This section will be short. There are a few problems I looked into in the past week.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Implement divided edge bundling, as produced by &lt;a href=&quot;http://vis.stanford.edu/files/2011-DividedEdgeBundling-InfoVis.pdf&quot;&gt;Selassie et al. (2011)&lt;/a&gt;. I described this briefly in my previous blog post. The obstacle here is that there is not available d3 implementation of the algorithm. In fact, the only implementation I could find available was &lt;a href=&quot;https://github.com/kakearney/divedgebundle-pkg&quot;&gt;one for Matlab&lt;/a&gt;, produced by &lt;a href=&quot;http://kellyakearney.net/&quot;&gt;Kelly Kearny (University of Washington)&lt;/a&gt;. This might prove more difficult than the remaining time in this quarter allows, but I’ve started the process anyways and will see where it takes me.&lt;/li&gt;&lt;li&gt;Highlighting extraction. That is, making it apparent in the visualization when the model is simply copying. I’ve been playing around with things such as color to encode this, but haven’t settled on anything I like.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;More work to come!&lt;/p&gt;&lt;h4&gt;References&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;See, Abigail et al. “Get To The Point: Summarization with Pointer-Generator Networks.” &lt;em&gt;ACL&lt;/em&gt; (2017).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://vis.stanford.edu/files/2011-DividedEdgeBundling-InfoVis.pdf&quot;&gt;Selassie, David et al. “Divided Edge Bundling for Directional Network Data.” &lt;em&gt;IEEE Transactions on Visualization and Computer Graphics&lt;/em&gt; 17 (2011): 2354–2363.&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=33072535817f&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-05-16T06:58:49+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-3973266691169482239">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #8 Milestone: Advanced model attempt #2</title>
	<link>https://teamoverfit.blogspot.com/2018/05/8-milestone-advanced-model-attempt-2.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #8: 05/15/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;This week, we weren't able to make our model make better prediction on stock price movement.&lt;/span&gt;&lt;br /&gt;&lt;h3&gt;&lt;span&gt;We have tried:&lt;/span&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Improve initialization weights and bias&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Increase standard deviation so that the initial price prediction varies more preventing the model to be stuck at local minima&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Decrease bias so that the initial prediction are closer to the expected, and therefore, converge faster&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Tune hyperparameters of LSTM and try out different settings of data&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Number of time steps of RNN&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Size of dictionary&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Remove vocab that have high document frequency&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Number of LSTM hidden units&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Number of RNN layers&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Learning rate&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Dropout layer&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Visualize and investigate our prediction/training to have better understanding of our model&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Find out the top k words that have most weight for a given day&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Most of them do not seem to relate to stock price movement&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Compare the prediction/target graph for each epochs to see if the predictions are improving/convergin&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;&lt;span&gt;In progress and next steps:&lt;/span&gt;&lt;/h3&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Find good news data and write preprocessor&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Research on better featurizations&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Research on better model&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Add learning rate decay to our training&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Investigate the correlation between sentiment analysis of Tweets and stock price movement&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-05-16T06:37:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-6866691098285474093">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #7 Milestone: Advanced model attempt #1 (continued)</title>
	<link>https://teamoverfit.blogspot.com/2018/05/7-milestone-advanced-model-attempt-1.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #7: 05/09/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&lt;b&gt;Try Out Logistic Regression To Tune LSTM&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&lt;b&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cb-ecd9-d5e4-fdaf1add2bb5&quot; style=&quot;font-weight: normal;&quot;&gt;&lt;span&gt;From our previous model, which we classify the stock price movement as UP/DOWN/STAY, we noticed that during training often the loss will converge in less than 5 epochs and the predictions are either all UPs or all STAYs depending on the range of percent difference we classified as STAY. It seems like the model wasn’t able to learn much from the input data.&lt;/span&gt;&lt;/span&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&lt;b&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;span&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cc-42d1-70ab-45794e67af61&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Then, we tried to use logistic regression by making our RNN only has one output node and remove the softmax function. We also changed the loss function from Cross-Entropy to mean squared loss. This helps to predict the percentage of change of the stock price directly.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&lt;b&gt;&lt;span style=&quot;font-weight: normal;&quot;&gt;&lt;span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cc-6947-13f3-a833249311ac&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;With the new training method, the model can now predict a specific stock price for a day given input data. Then, according to the stock price predicted, we can further categorize the prediction into UP/DOWN/STAY and use our previous evaluation function to determine the accuracy of our model.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;Select and Add Competitors Stock Price to Tune LSTM&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cd-277f-263a-f85ae0ec0c14&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;For company Apple, we selected company Samsung’s and Huawei’s stock prices as part of input data to train the model, because this two big company also produce mobile phones and are the biggest competitors for Apple in the industry.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cd-46f5-47b8-55814d42e5b3&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;For company Tesla, we selected company Toyota for the similar reason as for Apple.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;Results&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cd-a926-74ae-e30f944bf03e&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;After we have improved the model and the training process, it no longer generates the same classification for all input. It now does try to predict the stock price percent difference and has reasonable results.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cd-bab2-93f6-880e4aaa0b8c&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;The prediction accuracy for Apple will be around &lt;/span&gt;&lt;span style=&quot;font-weight: 700; vertical-align: baseline;&quot;&gt;55.5&lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;% if we choose &lt;/span&gt;&lt;span style=&quot;font-style: italic; vertical-align: baseline;&quot;&gt;‘+/-0.5% change of the stock price&lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt; as &lt;/span&gt;&lt;span style=&quot;font-style: italic; vertical-align: baseline;&quot;&gt;‘STAY’.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span style=&quot;font-style: italic; vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43cd-d22c-ec0c-0e76e203c53a&quot;&gt;&lt;span style=&quot;font-style: normal; vertical-align: baseline;&quot;&gt;The prediction accuracy for Apple will be above &lt;/span&gt;&lt;span style=&quot;font-style: normal; font-weight: 700; vertical-align: baseline;&quot;&gt;44.4&lt;/span&gt;&lt;span style=&quot;font-style: normal; vertical-align: baseline;&quot;&gt;% if we choose &lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;‘+/-1.0% change of the stock price’&lt;/span&gt;&lt;span style=&quot;font-style: normal; vertical-align: baseline;&quot;&gt; as &lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;‘STAY’.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;What to Investigate for the Next Week&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Try to use CNN as model.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Instead of using Tweets, try using financial news as input.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Try out different embedding methods.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43ce-cc90-1d5a-b707d0e7eb84&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;Apply F1 Scores. For the evaluation, we would like to know:&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;The rate of stocks are marked ‘UP’/’DOWN’/’STAY’ that are predicted correctly as ‘UP’/’DOWN’/’STAY’ separately.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-bd404b7a-43ce-fb74-a644-3c307522369d&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;The rate of stocks are marked ‘UP’/’DOWN’/’STAY’ that are predicted wrongly as ‘UP’/’DOWN’’STAY’&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-05-09T06:54:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/a2d837ecf66b">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 07: Formalizing</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-07-formalizing-a2d837ecf66b?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;previous posts: &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;&lt;em&gt;01&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;&lt;em&gt;02&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3&quot;&gt;&lt;em&gt;03&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-04-first-steps-be87c31976b7&quot;&gt;&lt;em&gt;04&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-05-experimenting-306dca636d3a&quot;&gt;&lt;em&gt;05&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-06-uncertainty-6f773ae418d0&quot;&gt;&lt;em&gt;06&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A couple of developments since I last posted:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;I’m now more formally receiving guidance from Kanit (Ham) Wongsuphasawat and Tongshuang (Sherry) Wu of the Interactive Data Lab. Special thanks to them for helping me thus far!&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-06-uncertainty-6f773ae418d0&quot;&gt;Last week&lt;/a&gt; I was uncertain as to the future direction of this project. After much deliberation and several conversations, I’ve decided to remain on the tool-based approach originally conceived. There are a couple reasons for this. First, the user study I proposed has, at least from an NLP perspective, limited novelty. What’s more, learning from the study by modifying the underlying model would require time that would likely fall outside of the quarter. Second, carrying out this study would involve significant logistical work (again, a time constraint). Finally, in beginning to formalize this visualization tool, I’ve become more excited in its potential as a useful part of a researcher’s debugging pipeline. In any case, any model modifications I may make as part of the user study would difficult without a similar tool.&lt;/li&gt;&lt;li&gt;As mentioned, I’ve been formalizing this tool in a React application, iterating on the exploration I’ve done with prototypes in the weeks previous. The rest of this post will describe my work here.&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;Starting with Text&lt;/h4&gt;&lt;p&gt;First things first: text brushing is critical in understanding the attention each output token, or a series of output tokens, pays to the source text. In the gif below, the left side holds the source text (along with a mini-map to prevent the need of scrolling to understand the overall distribution of attention), while the right holds the summary. Selection and brushing have been implemented, as in the prototypes of last week, albeit cleaned up.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/999/1*LKOEMB1cwvp2qXRy58_-4w.gif&quot; /&gt;Cleaned up selection and brushing, in addition to a minimap for long input sequences.&lt;/figure&gt;&lt;h4&gt;&lt;strong&gt;Challenges with Text (Future Work):&lt;/strong&gt;&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;Sentence / paragraph level structure is lost via tokenizing. This is an artifact of the tokenization process performed prior to feeding text into models.&lt;/li&gt;&lt;li&gt;Lowercase and always-on spacing between tokens makes text difficult to read. For now, I’ve been dealing this with a few hand-coded rules. For example, removing spaces before punctuation, and capitalizing the first word after end of sentence punctuation.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I’ll need to keep brainstorming to find methods for addressing these issues.&lt;/p&gt;&lt;h4&gt;How do we enable identification of patterns?&lt;/h4&gt;&lt;p&gt;While selection and brushing over the text is valuable in allowing users to understand attention for specific words or phrases, it falls short in enabling big-picture identification of patterns. Without brushing over each token and / or sentence (and memorizing coverage along the way), the closest users may get is the aggregate view (when nothing is selected) in which &lt;strong&gt;what&lt;/strong&gt; is being attended to is apparent, but not &lt;strong&gt;how.&lt;/strong&gt; That is to say, it is not apparent which tokens / phrases in the summary attend to which tokens / phrases in the source text. In particular, below is a growing list of goals for this visualization.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Enable identification of coverage&lt;/strong&gt;. For words / phrases / sentences, where is the attention being paid, and by what?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enable identification of missing coverage&lt;/strong&gt;. What is being unattended to that should be?&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Enable identification of extraction vs abstraction&lt;/strong&gt;. Where is copying occuring? Where is true abstraction occuring?&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;If this tool can accomplish these items, I believe it will be a good start in proving its value.&lt;/p&gt;&lt;p&gt;With this in mind, we need some sort of visualization to accompany the two blocks of text. As previously mentioned, heat-maps may not be the best solution.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*Kd4lr3ZZmOZ6ffMdp82PJg.gif&quot; /&gt;Interactive heat-map, as prototyped previously.&lt;/figure&gt;&lt;p&gt;Lag is apparent (likely a result of the large number of elements drawn), and even ignoring this, the tiles become extremely small as the input / output sequences grow, making it difficult to pick out even high attention weights. More visual weight is needed for significant attention weights, which is difficult to accomplish as x and y space is already taken by the input / output token position.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;So where else can we look?&lt;/strong&gt;&lt;/p&gt;&lt;h4&gt;Flowmaps&lt;/h4&gt;&lt;p&gt;Looking back at my project proposal, I saw this visualization made by Rikters et al. (2017).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*uP_-gGiPkv6YMFYz.&quot; /&gt;An example of a flow-map from machine translation [Rikters et al. 2017].&lt;/figure&gt;&lt;p&gt;I thought this might be worth exploring, so I attempted to create something similar.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*SxZUaHFYssV5JtXo.&quot; /&gt;A flowmap displaying all edges is problematic. This doesn’t scale either.&lt;/figure&gt;&lt;p&gt;Unsurprisingly, there are far too many edges to display without significant overlap and occlusion. Summarization rears its head again as a challenge with its large input sequences.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How do we remedy this?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;One observation is that high attention weights are fairly sparse (as evident by the aggregate on the source text above). What if we filtered out these insignificant weights? A naive approach is to take the top &lt;em&gt;k &lt;/em&gt;percent of weights and display only those.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*I4jiiM98R88ZfMKz.&quot; /&gt;A flowmap showing only the top 1% of weights.&lt;/figure&gt;&lt;p&gt;The above example is displaying only the top 1% of attention weights. Edges have both their width and opacity scaled by their weight within this 1% domain. Significant (wide) weights are clearly identifiable. Thinner lines, faint (or nearly invisible) lines can also be seen, indicating that the much more significant weights have been preserved. Four distinct ‘rays’ can be seen, seemingly corresponding to the four sentence of the summary.&lt;/p&gt;&lt;p&gt;Selection and brushing seemed like intuitive follow-ups for interaction to enable more detailed / accurate pattern identification.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Selection&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1000/1*U8_42zGX24nN8iB7Wo-zPw.gif&quot; /&gt;Selection over the flowmap, both over the output nodes as well as the output text.&lt;/figure&gt;&lt;p&gt;Selection allows users to orient themselves in the flowmap, picking out which edges correspond to which input / output tokens.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Brushing&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1000/1*1t7BRJX9g2k80B67IFQ4lw.gif&quot; /&gt;Brushing over the flowmap allows for windowed pattern identification.&lt;/figure&gt;&lt;p&gt;Brushing enables accurate pattern identification. In the example above, brushing over the distinct rays allows us to see the almost entirely extractive nature of the summary — there is a clear 1:1 mapping from input to output that is implied by the clean structure of the rays, and confirmed upon inspecting the corresponding input / output tokens for these rays.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;Challenges with Flowmaps (Future Work):&lt;/strong&gt;&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Selecting a top k% is not ideal — it does not generalize well.&lt;/strong&gt; In the pathological case, where attention is evenly distributed for all tokens, we lose a lot of valuable information. A potential band-aid to this is to allow users to select the percentage of weights displayed, but this may be dangerous as high percentages can crash the browser. Perhaps a more elegant solution would be to perform clustering on the weights. I’ll need to do more research here.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Overlapping paths can make reading the flowmap difficult.&lt;/strong&gt; The example shown above is fairly clean, direction flows, for the most part, in a single direction. You could imagine, however that if a summary is extremely abstractive, pulling from all over the source, there might be significant overlap in edges, decreasing legibility. A potential solution to this is edge bundling, where edges going in similar directions are pulled together to preserve pattern recognition.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;A good starting point for exploration here is the paper &lt;a href=&quot;http://vis.stanford.edu/files/2011-DividedEdgeBundling-InfoVis.pdf&quot;&gt;&lt;em&gt;Divided Edge Bundling for Directional Network Data&lt;/em&gt;&lt;/a&gt; by Selassie, Heller, &amp;amp; Heer (2011). In this, the authors describe a method for bundling, divided edge bundling, that holds characteristics I believe are important for my own visualization.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/0*Ma6OlxvATqGNHbyu.&quot; /&gt;Different techniques applied to a network of GitHub contributions along the west coast of the United States [Selassie, Heller, &amp;amp; Heer 2011].&lt;/figure&gt;&lt;p&gt;In the coming weeks I hope to dive into these techniques and explore their impact on the flowmap I’ve developed thus far.&lt;/p&gt;&lt;h4&gt;In Summary&lt;/h4&gt;&lt;p&gt;Still a lot of work to do! Here are my goals for the next week.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Improve flowmap visualization.&lt;/li&gt;&lt;li&gt;Find examples that cover the problem space (e.g. low coverage, abstraction, extraction).&lt;/li&gt;&lt;li&gt;Keep brainstorming.&lt;/li&gt;&lt;li&gt;Optimize code.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Things are getting interesting!&lt;/p&gt;&lt;h4&gt;References&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://ufal.mff.cuni.cz/pbml/109/art-rikters-fishel-bojar.pdf&quot;&gt;Rikters, Matīss, Mark Fishel, and Ondřej Bojar. “Visualizing neural machine translation attention and confidence.” &lt;em&gt;The Prague Bulletin of Mathematical Linguistics&lt;/em&gt; 109.1 (2017): 39–50.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://vis.stanford.edu/files/2011-DividedEdgeBundling-InfoVis.pdf&quot;&gt;Selassie, David et al. “Divided Edge Bundling for Directional Network Data.” &lt;em&gt;IEEE Transactions on Visualization and Computer Graphics&lt;/em&gt; 17 (2011): 2354–2363.&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=a2d837ecf66b&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-05-09T06:48:30+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="https://medium.com/p/6f773ae418d0">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 06: Uncertainty</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-06-uncertainty-6f773ae418d0?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;previous posts: &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;01&lt;/a&gt; &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;02&lt;/a&gt; &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3&quot;&gt;03&lt;/a&gt; &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-04-first-steps-be87c31976b7&quot;&gt;04&lt;/a&gt; &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-05-experimenting-306dca636d3a&quot;&gt;05&lt;/a&gt;&lt;/p&gt;&lt;p&gt;I’ve begun to realize I may not be getting as much out of the project I chose I had hoped. My initial motivation for my project was a hope of expanding my knowledge and developing insights on the NLP front by leveraging the familiarity of Visualization. While I am certainly learning a lot by reading papers on Attention and Neural Networks as a whole (especially through my in-class paper presentation), I feel the work I am doing in building a tool for visualizing and debugging attention models may not be providing me the space to explore NLP that I had hoped for. While the tool will certainly &lt;strong&gt;enable &lt;/strong&gt;exploration, my concern is that this exploration will not occur until after the tool is completed at the end of the quarter.&lt;/p&gt;&lt;p&gt;The good news is that there have been two recent developments that, while increasing my uncertainty, offer potential for greater depth in exploration along the NLP front.&lt;/p&gt;&lt;h4&gt;1. Potential Pivot&lt;/h4&gt;&lt;p&gt;I voiced these concerns with Prof. Choi this past week and was given a good amount of valuable advice. Per her suggestion, the beginning of my last cycle began with three tasks.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Read &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2470718&quot;&gt;&lt;em&gt;The Efficacy of Human Post-editing for Language Translation&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;authored by&lt;em&gt; &lt;/em&gt;Spence Green, Jeff Heer, and Christopher Manning. This paper is unique in that it presents the value of Visualization and HCI within Natural Language Processing, but not as a window into a model. Rather, the authors explore a specific task integral to the Language Translation pipeline and present suggestions for future work in improving Language Translation.&lt;/li&gt;&lt;li&gt;Do in-depth human error-analysis of existing summarization models. I used examples from See et al.’s paper &lt;em&gt;Get To The Point: Summarization with Pointer-Generator Networks &lt;/em&gt;(2017).This was helpful gaining a better intuition as to the problem space and the challenges currently posed by machine summarization.&lt;/li&gt;&lt;li&gt;Think about how summarization as a task, whether that be the development of models, the model’s task itself, or end-user tasks that use the model, can be re-framed in order to leverage Visualization. This was especially time consuming, as it was difficult for me, but it helped immensely in taking a step back to understand the purpose of these models. This, in turn, helped me understand how my work can fit into this purpose.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The next few days consisted largely of brainstorming pivots for my project. The most promising direction that came out of these sessions is very briefly outlined below.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Assisted Cognitive Document Abstraction&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Machine-generated document summaries, even the state-of-the-art, are infrequently used in practice because their summaries are quite poor. Perhaps we can leverage existing models to, rather than produce definite summaries which may be error-prone or difficult to understand, create visualizations over the source text in order to assist humans in comprehension and abstraction.&lt;/p&gt;&lt;p&gt;For example, instead of treating attention weights as input for an output of text, as we do in summarization models, we can view them as output for human interpretation. Aggregate attention distributions (in summarization) highlight areas of the input text that are salient for the summary produced. Note that this is potentially more valuable than highlighting extractive summaries in the text because attention could potentially point towards different areas of the text that relate to a summary sequence. In this way, generation of summaries becomes a proxy task for creating salient highlights for text. We could then use this as a starting point from which ‘related’ sections in an article may be highlighted for users upon interaction (e.g. mousing over an attended-to sequence).&lt;/p&gt;&lt;p&gt;The hope is that these visualizations will increase the speed (over no summarization) or accuracy (over machine summarization) at which readers can abstract / understand key ideas in a document.&lt;/p&gt;&lt;p&gt;Most excitingly, with this re-framing of the task for these models, from sequence output to highlighting, perhaps the models can be modified by adding or removing constraints and mechanisms in order to improve performance for this new task.&lt;/p&gt;&lt;p&gt;Upon presenting this idea (in longer form) to Prof. Choi, I was encouraged to (1) think more about weaknesses of removing summaries altogether and (2) push for more novelty in the approach — is there any meaningful insight about attention models or summarization as a task that can be gleamed from this pivot, and if not, how can I work towards that. While I do not yet have answers to these concerns, the next development may result in a few.&lt;/p&gt;&lt;h4&gt;2. Related work, here at the Allen School&lt;/h4&gt;&lt;p&gt;It was just recently brought to my attention that a Tongshuang (Sherry) Wu, a PhD student in the Interactive Data Lab (in which I am currently working), is also working on visualizations for understanding attention models in NLP. As a part of her project, she and a few of her peers have developed a preliminary visualization tool for an attentive QA model (on the SQuAD dataset).She and my mentor, Kanit (Ham) Wongsuphasawat (whom I have been bouncing ideas off recently), have kindly offered to meet and discuss her work and insights on the problem space. Perhaps collaboration is a possibility — this is exciting! In any case, I suspect talking with Sherry and Ham will provide me the insight and guidance to make a decision on the direction of my project.&lt;/p&gt;&lt;h4&gt;&lt;strong&gt;Future Work&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;I hope to make another blog post in the coming few days as I iron out a future direction. Before this, however, future work is unclear. Until next time!&lt;/p&gt;&lt;h4&gt;In the meanwhile (supplementary material)&lt;/h4&gt;&lt;p&gt;I’ve also been playing around with my visualization prototypes, even as I am uncertain as to whether or not they will be relevant to my project after this week. Here’s what I’ve discovered and implemented in that time.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Interactive heat-maps likely won’t work.&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*_bVKvDPn6jBADKwFU9VG3g.gif&quot; /&gt;Interactive heat-maps result in a large degree of lag between input and visual update. This is likely due to the extremely large size of the attention matrix in summarization (24,000 individual squares in the heat-map).&lt;/figure&gt;&lt;p&gt;This is unfortunate, but browser limitations are limitations that must be worked around.&lt;/p&gt;&lt;p&gt;2. Selection over output text.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/999/1*KfMQd6YnDzdH9dZOyjVEIw.gif&quot; /&gt;Mousing over words in the summary results in a view of the attention distribution over the article for that decoder time-step.&lt;/figure&gt;&lt;p&gt;This is similar to the interactive visualizations presented by See et al. in their &lt;a href=&quot;http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html&quot;&gt;blogpost&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;3. Brushing over output text.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1000/1*nwGIF3VgNDeuFxRml8gGzg.gif&quot; /&gt;Brushing over the summary results in an aggregate attention distribution (i.e. coverage) over the article for the selected decoder time-steps.&lt;/figure&gt;&lt;p&gt;This is an interaction technique I have yet to see in work involving attention analysis, so this is exciting! It looks to be somewhat useful in identifying sections of input text that are salient to an &lt;strong&gt;idea&lt;/strong&gt; rather than a &lt;strong&gt;single word&lt;/strong&gt; in the output text.&lt;/p&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=6f773ae418d0&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-05-02T06:59:16+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-3361785683406757277">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #6 Milestone: Advanced model attempt #1</title>
	<link>https://teamoverfit.blogspot.com/2018/05/6-milestone-advanced-model-attempt-1.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #6: 05/01/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;This week, we added more data source and have finer process of the data. We also convert &lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;Keras model to Tensorflow for better future improvement.   &lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;b&gt;Keras to TensorFlow&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;We updated our code from using Keras to Tensorflow which helps to do more improvement on model. For example, TensorFlow is a lower level library which allow us to have more control over the variables we used as the input and output. For example, if we want to try with more complicated input with adding the voerall market stock price and the competitors' stock prices, TensorFlow will be more helpful.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Add One More Target Company: Tesla&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;As there are too many Tweets that have tagged #Apple but are unrelated to the company Apple, we need to filter out such tweets. However, if we apply the model on the company Tesla, who's company name is uniquer than 'Apple' and has its products naming closer to its company name, the Tweets and news that have tagged #Tesla will contain much less noisy information and thus improve the prediction to its stock price.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Try Out Different Layers Structure to Tune LSTM&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul&gt;&lt;span id=&quot;docs-internal-guid-1d495372-1f45-7a06-476d-fd5b4661d619&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Add the NASDAQ index to the input&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;The composition of the NASDAQ Composite is heavily weighted towards information technology companies. Therefore, company Apple’s and Tesla’s stock prices may be influenced by the Nasdaq index.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Add a 'STAY' category as the output prediction of stock price&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span&gt;If the change of the stock price for the next day is within 1%, we will mark the stock price of that day as a ‘STAY’. Otherwise, we mark it as ‘UP’ or ‘DOWN’&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Lemmatization &amp;amp; Stemming&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Lemmatization and stemming help collect the same words with different tenses together, which reduce the total vocabulary size.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/span&gt;&lt;/ul&gt;&lt;div&gt;&lt;span id=&quot;docs-internal-guid-1d495372-1f45-7a06-476d-fd5b4661d619&quot;&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;Update Of Evaluation Plan&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span id=&quot;docs-internal-guid-1d495372-1f45-7a06-476d-fd5b4661d619&quot;&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;Results &amp;amp; Error Analysis&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;span id=&quot;docs-internal-guid-1d495372-1f45-7a06-476d-fd5b4661d619&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;After we have improved the model and the training process, the prediction accuracy for Apple will be above 85% if we choose '&lt;i&gt;+/-1% change of the stock price&lt;/i&gt;' as 'STAY'.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;The prediction accuracy for Apple will be above 60% if we choose '&lt;i&gt;+/-1% change of the stock price&lt;/i&gt;' as 'STAY'.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/span&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;span id=&quot;docs-internal-guid-1d495372-1f45-7a06-476d-fd5b4661d619&quot;&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;b&gt;What To Investigate For The Next Week&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;span id=&quot;docs-internal-guid-1d495372-1f45-7a06-476d-fd5b4661d619&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Apply F1 scores. For the evaluation ,we would like to know:&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;The rate of stocks are marked 'UP/DOWN/STAY' that are predicted correctly as 'UP/DOWN/STAY' separately.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;The rate of stocks are marked 'UP/DOWN/STAY' that are predicted wrongly as 'UP/DOWN/STAY' separately.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;Add competitors' stock prices to the input&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/span&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-05-02T05:53:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/306dca636d3a">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 05: Experimenting</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-05-experimenting-306dca636d3a?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;previous posts: &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;&lt;em&gt;01&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5\&quot;&gt;&lt;em&gt;02&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3&quot;&gt;&lt;em&gt;03&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-04-first-steps-be87c31976b7&quot;&gt;&lt;em&gt;04&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Hi! Here’s what I’ve been up to in the past week.&lt;/p&gt;&lt;h4&gt;Progress on the TensorBoard Plugin&lt;/h4&gt;&lt;p&gt;Real data collection and the backend are functioning!&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*l6M8uMcswVoaEtL0_HGt0w.png&quot; /&gt;Architecture of the Attention Plugin.&lt;/figure&gt;&lt;p&gt;At this point last week, I had implemented the nodes in green above. These were the operators / functions required to produce Summary protobufs that are in turn saved to disk.&lt;/p&gt;&lt;p&gt;This week, I completed a number of tasks to produce a bare-bones functioning plugin (sans visualizations).&lt;/p&gt;&lt;p&gt;First, I modified the source code for &lt;a href=&quot;https://github.com/abisee/pointer-generator&quot;&gt;See et al.’s (2017) attentional models&lt;/a&gt; to use the Attention Plugin API to save input text, output text, and attention distributions during evaluation.&lt;/p&gt;&lt;p&gt;Next, I implemented the Attention Plugin’s back-end, which is used to fulfill requests made by the front-end. This service currently offers two services:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;tags This route returns all tags associated for each run in the log. This should include 3 tags for each run: one for each of the input, output, and attention tensors.&lt;/li&gt;&lt;li&gt;attention This route returns a list values associated with the given tag (including time and step stamps). This can be used by the front-end to acquire each of the input, output, and attention lists (converted from tensors) by passing the corresponding tag (retrieved using the tags route).&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Finally, as a proof of concept, I modified the front-end provided in the &lt;a href=&quot;https://github.com/tensorflow/tensorboard-plugin-example&quot;&gt;TensorBoard Plugin Example&lt;/a&gt; to consume this back-end, showing it is able to retrieve summaries. Now we just need some visualizations to consume the data!&lt;/p&gt;&lt;h4&gt;Visualization Prototyping Begins&lt;/h4&gt;&lt;p&gt;While data collection and back-end development has been wrapping up, I’ve begun to prototype static visualizations for the plugin. To do this, I used data produced by &lt;a href=&quot;https://github.com/abisee/pointer-generator&quot;&gt;See et al.’s (2017) pre-trained attentional models&lt;/a&gt; (produced only at decode time without the Attention Plugin). Through this process, I hope to gain two things in particular.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;A idea of what will/won’t work as visualizations for summarization tasks.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;A better understanding of the behavior of attentive models&lt;/strong&gt;, and through that a better idea of how static and/or interactive visualizations can further interpretability and understanding.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The first idea I decided to pursue was that of a &lt;strong&gt;condensed heat-map&lt;/strong&gt;. You may recall the conventional heat-map used for attention visualizations described in &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;my first blog post&lt;/a&gt;.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/612/1*_sq2Vy_Py7hEXp2tWBBXxg.png&quot; /&gt;Rikters et al. (2017). A heat-map with relatively large cells, allowing for display of text along the axes.&lt;/figure&gt;&lt;p&gt;The issues I noted with this visualization pattern are as follows:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;It is difficult to fit the words (as seen above) on the x-axis, harming readability.&lt;/li&gt;&lt;li&gt;This does not scale well with large input or output (e.g. summarization)&lt;/li&gt;&lt;li&gt;We do not read single-tokens at a time (i.e. y-axis), and input and output are generally not in this format either.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;To address the point (2), scalability, I decided to try producing a heat-map with no text labels, and thus each cell could be as small as a single pixel.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*WOlVYgmeZ0DmutTZkDXn2g.png&quot; /&gt;A prototype of a condensed heat-map, where x-axis represents input and y-axis represents output.&lt;/figure&gt;&lt;p&gt;The color scale is a discrete scale, where each step is determined by the quantiles of the weight distribution. The x-axis represents the input text, and the y-axis represents the output text, with each cell representing the amount of attention paid for that pair (output paid to input). The good news here is that the attention distribution is relatively easy to understand at a quick glance. The downside is that cells that are not part of a larger trend (you may notice a lone red spot near the top of the heat-map, approximately a quarter of the way through the x-axis) are harder to make out, as the cells are so small. Further, the distribution is contextless — we don’t know the structure of the input text or what words these high weights are associated with. In the example above, we understand that the model focused primarily on the beginning of the article, but we can’t tell whether that is good or bad without seeing the text.&lt;/p&gt;&lt;p&gt;To remedy this, I decided to also display the input text, with the input text highlighted according to the maximum of the weights it received. This also solves concerns (1) and (3) for the conventional heat-map.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*dJXS9s_391dACPuUwAgPmA.png&quot; /&gt;The input text corresponding to the heat-map above, where each token is highlighted according to its max attention weight received.&lt;/figure&gt;&lt;p&gt;By putting these two together (along with the output text for reference), we can gain a better understanding of how the model arrived at its summary. A viewer can now map the attention distribution shown in the heat-map to text in the input sequence by looking for patches of similar color intensity.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*dMqdcl01Za5U4nYrXpye6g.png&quot; /&gt;A prototype static visualization including both heat-map and highlighted text.&lt;/figure&gt;&lt;p&gt;To get a better sense of how this visualization pattern would play out, I built a light web-page that allows users to cycle through different input / output examples. The gif below shows several of these.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*_ACE44hvUSrwfE3F04gslg.gif&quot; /&gt;The described visualization pattern over several input / output sequences.&lt;/figure&gt;&lt;p&gt;More exploration (inside and outside of this pattern) will need to occur, but this seems promising!&lt;/p&gt;&lt;h4&gt;What’s Next&lt;/h4&gt;&lt;p&gt;Lots to get done this next week. Here’s what’s in my plan:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Continue working on data collection and cleaning up the TensorBoard plug-in. Move beyond the proof-of-concept front-end and show that meaningful visualizations (perhaps extremely basic ones) can be generated using the plugin back-end as a data source.&lt;/li&gt;&lt;li&gt;Read more into the model provided by See et al. (2017), as well as related work, to gain a better understanding of the architecture and function/behavior of attention. A closer study of the works cited in my &lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;second blog post&lt;/a&gt; will be a good starting point. The better I understand this mechanism the more equipped I’ll be to create meaningful visualizations.&lt;/li&gt;&lt;li&gt;Continue prototyping static visualizations, move on to interactive visualizations. Acquire feedback from peers for both.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Thanks for reading!&lt;/p&gt;&lt;h4&gt;Works Cited&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;See, Abigail et al. “Get To The Point: Summarization with Pointer-Generator Networks.” &lt;em&gt;ACL&lt;/em&gt; (2017).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://ufal.mff.cuni.cz/pbml/109/art-rikters-fishel-bojar.pdf&quot;&gt;Rikters, Matīss, Mark Fishel, and Ondřej Bojar. “Visualizing neural machine translation attention and confidence.” &lt;em&gt;The Prague Bulletin of Mathematical Linguistics&lt;/em&gt; 109.1 (2017): 39–50.&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=306dca636d3a&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-04-25T06:48:23+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-597849658553454254">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #5 Milestone: Strawman/Baseline II</title>
	<link>https://teamoverfit.blogspot.com/2018/04/5-milestone-strawmanbaseline-ii.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #5: 04/24/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;&lt;span id=&quot;docs-internal-guid-8a395488-fb3a-d9a7-cec2-8d3cb31f0a59&quot;&gt;&lt;span&gt;This week, we tried to use tf-idf and seq2vec to process news headlines as input to our LSTM &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;model to predict UP/DOWN for APPLE stock price.&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;&lt;b&gt;Data Preprocessing&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Crawling historical news headlines from Twitter&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Categorize tweets with date and correlated stock price&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Cleanup unrelated data&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Map vocabulary to index with removing words that appear less than 3 times in the tweet news corpus.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Seq2One with TF-IDF&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;TF-IDF&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Correlate word frequencies with price changes (convert words into normalized frequency count vector)&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Seq2One&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Correlate average word embeddings with price changes (convert words into normalized embedding vector)&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Bidirectional RNN&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Enhance the performance by knowing before and after prices&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Evaluation&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Accuracy on predicting Up or Down&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Accuracy on predicting Stock Price (TODO)&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Result&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;TF-IDF: 60.7% accuracy predictin UP/DOWN on test set with 273 total data points and 9/1 train-test split&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Seq2Vec: 53.6% accuracy predicting UP/DOWN on test set with 273 total data points and 9/1 train-test split&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Error Analysis&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;b&gt;Things that may impair the precision of prediction&lt;/b&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Words with high frequency but have low effect on stock prices:&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;A, is, of, for, the&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Tweets talking about fruit &lt;i&gt;apple&lt;/i&gt; instead of the company&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;Tweets news that have high frequency but low effect on stock prices and news that may have high effect on stock prices but with low frequencies&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Losing information of each single tweet as we have combined all tweets in a day together to form a word frequency vector and do the prediction&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;b&gt;Things that could be done to improve the performance&lt;/b&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Add the overall market stock price as part of the input because it usually also has big impact on a single companies stock price.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Crawl more data for more companies and longer duration&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Add financial&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Add the competitor companies stock prices and tweets news as part of the input.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span id=&quot;docs-internal-guid-8a395488-fb3c-6f01-c575-279c6f3d6421&quot;&gt;&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-25T05:20:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/be87c31976b7">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 04: First Steps</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-04-first-steps-be87c31976b7?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;previous posts: &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;&lt;em&gt;01&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;&lt;em&gt;02&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3&quot;&gt;&lt;em&gt;03&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Nearing 4 weeks in — I’ve finally got a foothold in the development process. Over this past week I’ve been looking through TensorBoard and TensorFlow source-code and documentation in an attempt to develop a foundation for plugin development.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Notable Resources:&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard&quot;&gt;TensorBoard Documentation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorboard&quot;&gt;TensorBoard Source Code&lt;/a&gt; and &lt;a href=&quot;https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins&quot;&gt;Existing Plugins&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/tensorflow/tensorboard-plugin-example/blob/master/README.md&quot;&gt;Developing a TensorBoard Plugin&lt;/a&gt; (a simple example)&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Completed Milestones:&lt;/h4&gt;&lt;ol&gt;&lt;li&gt;Understand the structure of a TensorBoard Plugin, specifically how the architecture of the Attention Plugin should look like.&lt;/li&gt;&lt;li&gt;Design and write the data fetching layer.&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;Plugin Architecture&lt;/h4&gt;&lt;p&gt;In TensorFlow, data from iterations of training / evaluation is stored as a set of &lt;strong&gt;summaries&lt;/strong&gt;. These can take the form of any tensor, including text, image, scalars, or time series. These are written to disk as the computation graph is executed. Each ‘summary’ takes the form of a &lt;a href=&quot;https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/summary.proto&quot;&gt;Summary protocol buffer&lt;/a&gt;, which holds, in addition to the data stored, critical identifying information (tags and metadata). A plugin can then read summaries associated with particular tags and sessions from disk to serve to the TensorBoard front-end via a plugin back-end, where a visualization is rendered.&lt;/p&gt;&lt;p&gt;Following &lt;a href=&quot;https://github.com/tensorflow/tensorboard-plugin-example/blob/master/README.md&quot;&gt;&lt;em&gt;Developing a TensorBoard plugin&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;the Attention Plugin with have three primary components:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Data API layer. This is what allows users to capture relevant summaries from within their models.&lt;/li&gt;&lt;li&gt;Plugin backend, which serves said summaries.&lt;/li&gt;&lt;li&gt;Frontend, where the visualizations are displayed.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Unlike commonly used plugins such as the &lt;a href=&quot;https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/scalar]&quot;&gt;scalar&lt;/a&gt; and &lt;a href=&quot;https://github.com/tensorflow/tensorboard/tree/master/tensorboard/plugins/histogram&quot;&gt;histogram&lt;/a&gt; plugins, the Attention Plugin consumes 3 distinct values: the input text, the decoded output text, and the attention matrix that correlates the two. Initially, I attempted to store these all in a single Summary protobuf, where the first two rows of the encapsulating matrix would contain the text, and the rest would contain the attention weights. This results in a mixing of string and float types in a single Tensor, which is not valid (to my knowledge) in TensorFlow. I then realized I could store these separately, each in their own summary, and retrieve them via an identifying name. The resulting architecture is shown in the diagram below.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*QK7USkxsSC3u6F0LKbKWXQ.png&quot; /&gt;The architecture of the Attention Plugin.&lt;/figure&gt;&lt;p&gt;I decided to make the output text an optional summary, as models don’t necessarily need to decode (via Viterbi, Beam Search, or otherwise) an output sequence while training. The input text and attention matrix are still valuable, as summary statistics (e.g. coverage, important words, etc) can be gleamed without the decoded text.&lt;/p&gt;&lt;h4&gt;Data API Layer&lt;/h4&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*0m1-fllpNYMP666FhR0nbA.png&quot; /&gt;Data API Layer highlighted in green.&lt;/figure&gt;&lt;p&gt;As the TensorBoard authors suggest, the data API layer, defined in attention_summary.py, provides two methods for creating Summary protobufs, which can then be written to disk via a FileWriter. The first is via a TensorFlow op, which can be thought of as a node in the computation graph, that produces a Summary when the graph is executed. The second is by directly creating the protobuf, which allows for data to be saved outside the execution of a TensorFlow session. I’ve implemented both of these. There is a separate method for each of the three datum used by the plugin (input text, output text, attention matrix), and each of the three summary datum are tagged differently (e.g. name/attention_input_summary, name/attention_output_summary) in order to allow for distinguishable retrieval later.&lt;/p&gt;&lt;p&gt;An example of the usage of both methods can be found in attention_demo.py.&lt;/p&gt;&lt;h4&gt;Next Steps&lt;/h4&gt;&lt;p&gt;I suspect the work completed this week was the biggest hurdle in terms of time:code ratio. I would not be surprised if I had to revisit the work done here in order to clean things up or fix small bugs. However, with this understanding and architecture nailed down, I expect implementation of the rest of the plugin will come at a faster pace. With that said, three tasks stand as immediate goals for the next week.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Modify my forked repository of the summarization model created by &lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;See et al.&lt;/a&gt; (original found &lt;a href=&quot;https://github.com/abisee/pointer-generator&quot;&gt;here&lt;/a&gt;) to produce and save the appropriate summaries for the Attention Plugin. I’ve already started looking into this, and expect to have to fiddle around with the training / evaluation scheme in order to grab an appropriate amount of data.&lt;/li&gt;&lt;li&gt;Implement the backend of the Attention Plugin.&lt;/li&gt;&lt;li&gt;Begin prototyping visualizations (pen &amp;amp; paper) and acquire preliminary feedback.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Until next time.&lt;/p&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=be87c31976b7&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-04-19T06:33:40+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-3753031463594823927.post-8569998071322028844">
	<title>Ron Fan, Aditya Saraf &lt;br/&gt; Team PrimeapeNLP: Blog Post #4</title>
	<link>https://cse481n.blogspot.com/2018/04/blog-post-4.html</link>
	<content:encoded>&lt;div dir=&quot;ltr&quot; id=&quot;docs-internal-guid-7937c8af-d777-ed0f-f77b-cf09623b985e&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;A big part of our work for setting up a baseline is the creation of a reasonably good dataset for training and evaluating extractive text summarization. Our goal was to build a dataset with all sentences from the articles marked with binary labels indicating whether or not they were part of the extracted summary.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;We used the DailyMail and CNN story dataset, which is meant for abstractive summarization, to build our own dataset. The data set includes automatically-parsed lines from news articles, as well as a few bullet point highlights for each article. These highlights are not sentences directly from the article, but are overall a decent indicator and considered to be one of the most useable datasets out there (if for no other reason than sheer volume of data).&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;To build our data set, we used a toy metric roughly based off of ROUGE-N, with the understanding that we would only need a way of relative ranking for each sentence.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;The procedure to generate the data set was as follows:&lt;/span&gt;&lt;/div&gt;&lt;ol style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Read in a single .story file from the abstractive dataset into highlights and sentences.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Post-process sentences- in the original data, new lines do not correspond exactly with sentence endings. Additionally, some sentences are originally split arbitrarily by new lines. We do an additional split by the regex (?&amp;lt;=[.?!])\s+ (whitespace with period, question mark, or exclamation mark lookbehind), but sentence “re-joining” is off by default, as some sentences in the original dataset do not end with punctuation.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Score each sentence with our metric.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;ol style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Tokenize each sentence and highlight.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Build unigram, bigram, and trigram lists.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Count the number of matches between the sentence and all the highlights, giving more weight to bigram and trigram matches and also weighting by word length.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Sort sentences by score.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Let S be the number of sentences and H be the number of highlights. The algorithm picks up to min(1, floor(S/2)) sentences as part of the summary. It picks at least the H sentences with the highest scores. After sentence H is picked, subsequent sentences will only be picked if their score was at least (80+3*X)% of the previously-picked sentence’s score, where X is the number of sentences currently picked. This is effectively a fairly arbitrary metric to pick the most likely sentences roughly in accordance with the size of the abstractive summary, while also allowing for particularly similar sentences to both be chosen for completeness.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;All data input and output with UTF-8 encoding.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Output format:&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;&amp;lt;#&amp;gt; &amp;lt;SENTENCE PLAINTEXT&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;# is either 0 = normal sentence in the article, 1 = sentence chosen as part of extractive summary, 2 = original abstractive summary (should not be touched by model, only left there for human reference). &lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Overall, we think our data set is generally reasonable and makes sense. Nonetheless, there are a number of weaknesses with both extractive models in general and this specific type of dataset (including some problems which derive from the original abstractive dataset).&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Key weaknesses of data set:&lt;/span&gt;&lt;/div&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;In the original data, highlights do not always correspond to actual information in the article. For example, this short story has four highlights that are all new information: 008fc24ca9f4c48a54623bef423a3f2f8db8451a.story.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Frequent formatting problems - sentences that don’t terminate with punctuation, repeated sentences, bugged unicode characters, etc.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Key weaknesses specific to extractive summarization:&lt;/span&gt;&lt;/div&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Articles that are particularly short are effectively impossible to meaningfully summarize with extractive techniques.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Some sentences in articles contain the same content with slightly different wording. In these cases, we decided to choose both sentences, with the idea that post-processing could take care of highly-similar sentences, but a model could not be expected to accurately distinguish between two such sentences if they have different labels.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;The Baseline Model:&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;For our baseline combinatorial approach, we did a simple Maximum Coverage Problem implementation. The Maximum Coverage Problem is a classic NP-complete problem. Given a collection of n sets, the goal is to maximize the number of chosen (or “covered”) elements while only choosing k of the sets (where k &amp;lt; n). It’s very straightforward to reduce summarization to this problem. The sentences in the document are the sets, and the vocabulary of the document represents the “universe”, or the elements in the sets. The goal is to cover as many words as possible while picking the same number of sentences as in the labelled summary. The intuition is that sentences with more words capture more semantic meaning, and once a word is listed in the summary, that word need not be considered again. This reduction makes some intuitive sense, but two main aspects must be refined. First, not all words are equally meaningful. Some words, like “a”, “the”, or “and”, have little semantic content, while named entities and other important words have much higher semantic content. Second, we should at least account for sentence lengths -- instead of constraining the algorithm to pick the same number of sentences, we should constrain it to the same word count. This two additional criteria turn the problem into the Budgeted Maximum Coverage Problem: elements in the sets have specified values, and the sets have specified costs. The new objective is to maximize the total value of the covered elements while remaining with a given budget.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Of course, this problem is NP-complete, so it may seem like a strange choice to model summarization with. There are two approaches to this. First, a simple greedy algorithm achieves an approximation of ~63%, which means that the greedy algorithm is guaranteed to get at least 63% of the value of the optimal solution. For the standard MCP, the greedy algorithm just chooses the set with the most uncovered elements until no more sets are allowed. For the budgeted MCP, the approximation algorithm is slightly more complex. See Khuller et al. for a detailed look at it -- the algorithm is slightly more work, but still very understandable, and achieves the same approximation bound.  We can also formulate the problem as an Integer Linear Program (ILP) and use an ILP solver to generate optimal solutions on realistic instance sizes. This works because the documents and sentences are both small.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;For now, we are using the greedy algorithm for the standard MCP. As a simple metric, we used the number of correct chosen sentences divided by the number of chosen sentences in total (correct means that the gold standard also picked that sentence). With a basic MCP approach, we had an accuracy of 0.218. This was measured on a small sample of 2000 stories. In order to approximate a weighting scheme, we use a stop list to simply remove common articles and other semantically empty words. With this small modification, we had an accuracy of 0.2328.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;We plan to extend this to a better baseline model in the next few days. We will formulate the problem as an ILP and pass it to an ILP solver for an optimal solution. We will also implement a more sophisticated weighting scheme. One idea is to use some of the labelled data as training data (right now, we don’t train) to build a weight matrix for common words -- we can build this matrix with a logistic regression, using n-gram (probably unigram) similarity as the loss function.This will hopefully give us a more reasonable baseline model.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Evaluation Framework:&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;For now, we’re using a simple accuracy metric. We plan to switch to ROUGE, which counts n-gram similarity (ROUGE measures recall, not precision). We will work with the ROUGE-2.0 Java package or pyrouge, depending on which language we are working with. &lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;So to summarize our goals for the next week, we will improve this baseline model by formulating the problem as an ILP and we may implement a weighting scheme (if that’s too complicated, we’ll save it for the advanced model). We will also build a baseline neural model. Then, we’ll flesh out our evaluation framework using ROUGE metrics, train/test using more of the corpus, and have detailed error analysis.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;References:&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Khuller, S., Moss, A., &amp;amp; Naor, J. (Seffi). (1999). The Budgeted Maximum Coverage Problem. &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Inf. Process. Lett.&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;, &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;70&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;(1), 39–45. https://doi.org/10.1016/S0020-0190(99)00031-9&lt;/span&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-18T06:25:00+00:00</dc:date>
	<dc:creator>Ron &amp; Aditya</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-1250926726356516395">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #4 Milestone: Strawman/Baseline I</title>
	<link>https://teamoverfit.blogspot.com/2018/04/4-milestone-strawmanbaseline-i.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #4: 04/17/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span&gt;This week, we experimented with crawling data by querying from Twitter website, but we had some struggles finding the meaningful data set. Firstly, the Twitter API does not support fetching tweets prior than 7 days, so we have to write bash scripts and use a crawler to strip data from website, which is comparatively slower.&lt;/span&gt;&lt;br /&gt;&lt;span id=&quot;docs-internal-guid-945a652a-d716-7ba2-4653-bdd5ec706d01&quot;&gt;&lt;a href=&quot;https://github.com/Jefferson-Henrique/GetOldTweets-python&quot;&gt;&lt;span&gt;https://github.com/Jefferson-Henrique/GetOldTweets-python&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;We tried to query keywords like Apple, iPhone, iPad. Lots of tweets we got are not in English, so we used language detection tools to filter out tweets in other languages. Unfortunately, there are too much giveaway and advertisement flooding on the platform. Some examples are:&lt;/span&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span&gt;&quot;Microsoft planning to launch Surface Pro 6 in first quarter of 2017&quot;&lt;/span&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span&gt;&quot;KFire TV Giveaway: Win a Microsoft Bluetooth Mouse. http://kodifiretvstick.com&quot;&lt;/span&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span&gt;&quot;Microsoft Releases The 'Studio', Its First Desktop Computer&quot;&lt;/span&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;span&gt;&quot;Like - free microsoft points world http://freemicrosoftpointsworld.weebly.com/&quot;&lt;/span&gt;&lt;/blockquote&gt;&lt;span&gt;Therefore, for out strawman model #1 we decide to use the relative news headlines under twitter search query.&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;We searched companies' names like Google, Microsoft, Tesla to find relative new headlines and use unigram (bag of words) to put it in a decision tree model with random forest mechanism to predict the price go UP or DOWN. We had mixed results using this model. This is just our first attempt to see whether the twitter data is useful to predict the movement of future stock prices.&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;AAPL GOOG MSFT AMZN&lt;/span&gt;&lt;br /&gt;&lt;span&gt;53.66% 58.53% 56.10% 37.50%&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;Next week, we'll try to use deep neural network as predictive model and expand our input to the user feedback of the product from general users.&lt;/span&gt;&lt;br /&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;/blockquote&gt;&lt;blockquote class=&quot;tr_bq&quot;&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-18T04:47:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/7d8e9ec1a8e3">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 03: Project Proposal</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-03-project-proposal-7d8e9ec1a8e3?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;em&gt;previous posts: &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;&lt;em&gt;01&lt;/em&gt;&lt;/a&gt;&lt;em&gt; &lt;/em&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5&quot;&gt;&lt;em&gt;02&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;Towards a Better Understanding of Neural Networks: Visualizing Attention in Sequence-to-Sequence Models&lt;/h3&gt;&lt;h4&gt;A brief review of attention&lt;/h4&gt;&lt;p&gt;The idea of ‘attention’ was first introduced to the sphere of natural language processing by Bahdanau et al. (2014) in &lt;em&gt;Neural machine learning by jointly to align and translate&lt;/em&gt;. The idea is fairly straightforward: if we have an encoder-decoder model, at each decoding time-step we generate a vector of attention weights corresponding to each of the encoding units. That is to say, when generating each output token, we pay ‘attention’ to certain parts of the input sequence. Intuitively, this is much how we as humans fixate on parts of text to perform tasks such as summarization or question answering.&lt;/p&gt;&lt;h4&gt;Why visualization?&lt;/h4&gt;&lt;p&gt;In Machine Learning, neural networks have always been a sort of black box. We know they work incredibly well in certain contexts, but its often difficult to understand why they work so well. The following quote sums up the need for interpretability quite well.&lt;/p&gt;&lt;blockquote&gt;&lt;strong&gt;&lt;em&gt;“I believe the most important direction for future research is interpretability.&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; The attention mechanism, by revealing what the network is “looking at”, shines some precious light into the black box of neural networks, helping us to debug problems like repetition and copying. To make further advances, we need greater insight into what RNNs are learning from text and how that knowledge is represented.”&lt;/em&gt;&lt;/blockquote&gt;&lt;blockquote&gt;- Abigail See, PhD - Stanford University, &lt;em&gt;‘So, is abstractive summarization solved?’&lt;/em&gt; from &lt;a href=&quot;http://www.abigailsee.com/2017/04/16/taming-rnns-for-better-summarization.html&quot;&gt;Taming Recurrent Neural Networks for Better Summarization&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;Visualization provides an avenue for interpretability by mapping the behavior of the complex networks to easy-to-understand visual encodings.&lt;/p&gt;&lt;h4&gt;A survey of related work&lt;/h4&gt;&lt;p&gt;Although I am not aware of any papers dedicated to the visualization of attention, examples can be readily found in both published literature and online blogposts. For each example below, I’ll point out strengths and weaknesses. Ultimately, I hope to show that there are improvements we can make that can augment the interpretability of the workings of seq2seq attentional models.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Heat-maps&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/404/0*9FCWt3AO5oGxLxtg.&quot; /&gt;Bahdanau et al. (2014). An attention visualization for a seq2seq problem (in this case, translation). Whiter cells represent higher attention.&lt;/figure&gt;&lt;p&gt;The encoding scheme used by Bahdanau et al. (2014) themselves, heat-maps were the most common encoding of attentional data I found. While making the task of relative correlation lookup efficient, these have a couple of weaknesses.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Hard to scale. With tasks involving large input or output (e.g. a hundred or more tokens) the size of the heat-map quickly gets out of hand. Scrolling greatly decreases the effectiveness of a visualization with respect to analysis tasks.&lt;/li&gt;&lt;li&gt;Difficult to read. We generally don’t read in a token-per-line format. Furthermore, source text is rarely in a token-per-line format — we lose insightful information that could be drawn from analyzing the original structure of the text.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;strong&gt;Flow-maps&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*I3cdFcqDAcdKEwuCpAPHTA.png&quot; /&gt;Rikters et al (2017). The input sequence is seen on top — output on bottom. Thicker lines denote higher attention.&lt;/figure&gt;&lt;p&gt;Less common, but interesting nonetheless. This kind of flow-map suffers from problems similar to those of heat-maps. One could also argue that the thinness of the lines and their cross-hatch nature hinder interpretability.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Interaction&lt;/strong&gt;&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/800/1*3dTXvSI-L3X3M-MKXRraBA.gif&quot; /&gt;See et al. (2017). Interactive visualization of attention&lt;/figure&gt;&lt;p&gt;Interaction solves many of the issues of the static visualizations surveyed above. We retain the structure of both the input and output text, and lookup is quick and efficient. There is a trade-off, however. We are only able to view the attention of a single word at a time, and as a result it is hard to get a sense of the overall coverage or structure of attention.&lt;/p&gt;&lt;h4&gt;A case study: Summarization&lt;/h4&gt;&lt;p&gt;In particular,&lt;strong&gt; abstractive summarization&lt;/strong&gt;. Summarization is a particularly interesting use case of attention because of the requirement of the condensing of text. The hypothesis is that good abstractive models will be able to cover the majority of the original document. Here I note the difference between &lt;strong&gt;extractive &lt;/strong&gt;and&lt;strong&gt; abstractive &lt;/strong&gt;summarizations. The former involves selecting pieces of the original text, verbatim. The latter involves compressive paraphrasing.&lt;/p&gt;&lt;p&gt;Until recently, most of the work in text summarization has revolved around extractive summarization (See et al. 2017). However, the rising prevalence of recurrent neural networks has allowed for further focus in abstractive summarization. Attention has played an important role in improving results. Below is a brief list of relevant work.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1509.00685.pdf&quot;&gt;Rush, Alexander M. et al. “A Neural Attention Model for Abstractive Sentence Summarization.” &lt;em&gt;EMNLP&lt;/em&gt; (2015).&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1602.06023.pdf&quot;&gt;Nallapati, Ramesh et al. “Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.” &lt;em&gt;CoNLL&lt;/em&gt; (2016).&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1712.06100.pdf&quot;&gt;Hasselqvist, Johan et al. “Query-Based Abstractive Summarization Using Neural Networks.” &lt;em&gt;CoRR&lt;/em&gt; abs/1712.06100 (2017): n. pag.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.04304.pdf&quot;&gt;Paulus, Romain et al. “A Deep Reinforced Model for Abstractive Summarization.” &lt;em&gt;CoRR&lt;/em&gt; abs/1705.04304 (2017): n. pag.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;See, Abigail et al. “Get To The Point: Summarization with Pointer-Generator Networks.” &lt;em&gt;ACL&lt;/em&gt; (2017).&lt;/a&gt;&lt;/p&gt;&lt;h4&gt;Summarization Specific Challenges&lt;/h4&gt;&lt;p&gt;While visualizations of attention are helpful in shedding light on the workings of seq2seq models, summarization models in particular have trouble leveraging this window.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;We care about &lt;strong&gt;where&lt;/strong&gt; attention falls just as much as what it falls on. We hope to maximize &lt;strong&gt;coverage&lt;/strong&gt;. This is not currently addressed in any interactive visualizations I am aware of.&lt;/li&gt;&lt;li&gt;We have large input sequences. As discussed in &lt;strong&gt;“A survey of related work,”&lt;/strong&gt; this is particularly problematic for static visualizations.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;With this in mind, I propose areas for improvement in both interactive and static visualizations.&lt;/p&gt;&lt;h4&gt;Where to?&lt;/h4&gt;&lt;p&gt;With interactive visualizations, two things.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;One. Coverage &lt;/strong&gt;is the aggregated attention over a sequence of output tokens. An example given by See et al. can be seen in the figure below. Perhaps allowing brushing to visualizing the aggregate attention over a phrase or sentence can help us understand attention in a more global context.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/956/0*vE-iXohphbWY6Nam.&quot; /&gt;See et al. (2017). Example of coverage.&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Two. Extraction vs Abstraction: &lt;/strong&gt;Ideally, we want our model to learn how to abstract rather than extract. 1:1 exact match attention is less interesting to see than seeing attention to groups of words. Perhaps emphasizing / de-emphasizing can this in visualizations can help aid understanding of models.&lt;/p&gt;&lt;p&gt;With static visualizations, there are two analysis tasks that we wish to optimize for.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Summary. &lt;/strong&gt;What is the overall structure of the attention (e.g. coverage).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Value. &lt;/strong&gt;Which input words are attended (i.e. focused on) by each output timestep?&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;It is difficult to design an &lt;em&gt;effective&lt;/em&gt; static visualization that lends itself well to both of these tasks. Perhaps we need a set of visualizations. For example, one visualization might afford better performance for summary analysis, while another might afford better performance for value analysis. In addition, these static visualizations can incorporate ideas described in previous section.&lt;/p&gt;&lt;p&gt;Additionally, attention visualizations thus far have been for &lt;strong&gt;specific examples&lt;/strong&gt;. Perhaps there a way we can look &lt;strong&gt;across examples&lt;/strong&gt; to better understand the behavior of these neural networks. Derived metrics for attention or coverage could be useful in better understanding and diagnosing these models.&lt;/p&gt;&lt;p&gt;My hope is that addressing these items in both interactive and static visualizations will allow us to better reason about neural networks. In particular, I hope the result can be used as a valuable tool for error analysis, &lt;strong&gt;even&lt;/strong&gt; &lt;strong&gt;beyond&lt;/strong&gt; hyperparameter tuning. Insights could be gleamed that motivate additions or constraints or mechanisms to optimize coverage (e.g. See et al. (2017)) or abstraction.&lt;/p&gt;&lt;h4&gt;The Plan&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Minimum Viable Plan&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Develop a TensorBoard plugin that allows for the static and interactive visualizations described in &lt;strong&gt;Where to?&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;Acquire feedback from students / researchers in the Allen School.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I intend to leverage existing models to retrieve data. For example, that &lt;a href=&quot;https://github.com/abisee/pointer-generator&quot;&gt;provided publicly&lt;/a&gt; by See et al. (2017). The dataset used by them is a &lt;a href=&quot;https://github.com/abisee/cnn-dailymail&quot;&gt;modified CNN/Daily Mail Dataset&lt;/a&gt; [Hermann et al. (2015), See et al. (2017)] — a collection of articles and bullet point summaries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Stretch Goals&lt;/strong&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Explore and implement aggregate, cross-example visualizations as described in &lt;strong&gt;Where to?&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;Release a beta of the TensorBoard plugin on github and acquire feedback there.&lt;/li&gt;&lt;/ol&gt;&lt;h4&gt;Works Cited&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;See, Abigail et al. “Get To The Point: Summarization with Pointer-Generator Networks.” &lt;em&gt;ACL&lt;/em&gt; (2017).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02078.pdf&quot;&gt;Karpathy, Andrej, Justin Johnson, and Li Fei-Fei. “Visualizing and understanding recurrent networks.” &lt;em&gt;arXiv preprint arXiv:1506.02078&lt;/em&gt;(2015).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1712.06100.pdf&quot;&gt;Hasselqvist, Johan et al. “Query-Based Abstractive Summarization Using Neural Networks.” &lt;em&gt;CoRR&lt;/em&gt; abs/1712.06100 (2017): n. pag.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1602.06023.pdf&quot;&gt;Nallapati, Ramesh et al. “Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.” &lt;em&gt;CoNLL&lt;/em&gt; (2016).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.04304.pdf&quot;&gt;Paulus, Romain et al. “A Deep Reinforced Model for Abstractive Summarization.” &lt;em&gt;CoRR&lt;/em&gt; abs/1705.04304 (2017): n. pag.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1509.00685.pdf&quot;&gt;Rush, Alexander M. et al. “A Neural Attention Model for Abstractive Sentence Summarization.” &lt;em&gt;EMNLP&lt;/em&gt; (2015).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1409.0473.pdf&quot;&gt;Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. “Neural machine translation by jointly learning to align and translate.” &lt;em&gt;arXiv preprint arXiv:1409.0473&lt;/em&gt; (2014).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.03340.pdf&quot;&gt;Hermann, Karl Moritz et al. “Teaching Machines to Read and Comprehend.” &lt;em&gt;NIPS&lt;/em&gt;(2015).&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=7d8e9ec1a8e3&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-04-12T05:46:21+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-3753031463594823927.post-4531878816260312232">
	<title>Ron Fan, Aditya Saraf &lt;br/&gt; Team PrimeapeNLP: Blog Post #3</title>
	<link>https://cse481n.blogspot.com/2018/04/blog-post-3.html</link>
	<content:encoded>&lt;h1 dir=&quot;ltr&quot; id=&quot;docs-internal-guid-ea0c9d97-b369-9237-6f13-3675807d7a60&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 20pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 20pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Project Objectives&lt;/span&gt;&lt;/h1&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Single document summarization (SDS) is one of the remaining challenging problems in natural language processing. Novel methods are presented frequently in new papers, but they often do not include specific code allowing for reproducibility and are evaluated on specific datasets that make comparisons between models meaningless and difficult.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;There are many approaches to SDS, but they can be broadly divided into combinatorial approaches and neural approaches. Neural approaches build a neural architecture, such as a seq2seq/encoder-decoder model or single sequence RNNs. Combinatorial approaches will either try to frame the problem as an optimization problem, and then use an ILP solver, or frame the problem as a classic NP-hard problem, like Knapsack or Maximum Coverage. We want to explore both approaches, and compare their performance on the same dataset.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;SDS is comprised of two tasks: extractive summarization and abstractive summarization. Extractive summarization compiles a summary by selecting sentences from the document’s text while abstractive summarization generates text for the summary (sentences that may not have been present in the document’s text). While abstractive summarization might have more intuitive appeal, our project will focus on extractive summarization to enable meaningful comparisons between neural and combinatorial approaches (combinatorial approaches often must be extractive).&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;In this project, we plan to implement at least one neural and one combinatorial model for extractive single document summarization. We hope to establish some meaningful ways to compare the differences between selections made by the different types of models. Our primary goal is to better understand the strengths and weaknesses of neural and combinatorial models for single document summarization - a particular important aspect of SDS given the general roughness of existing evaluation metrics. We will gauge our progress based on reaching acceptable performance on commonly-used evaluation metrics when we implement models.&lt;/span&gt;&lt;/div&gt;&lt;h1 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 20pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 20pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Methodology&lt;/span&gt;&lt;/h1&gt;&lt;h3 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 4pt; margin-top: 16pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 13.999999999999998pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Minimal Viable Action Plan&lt;/span&gt;&lt;/h3&gt;&lt;ol style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Build our data set using existing data. Specifically, convert data better suited for training abstractive summarization models into data that can be used for extractive summarization..&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Implement a simple combinatorial model (for example, we can do a simple maximum coverage problem, where we set up the “universe” to be the vocabulary of the document, and treat the sentences as sets of words).&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Implement a simple neural model (just treat the problem as a generic binary classification problem).&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Train models on identical data sets and do a baseline comparison -- how well does a simple neural model do vs. a simple combinatorial model? This doesn’t tell us much about the relative strengths of the two approaches (we can’t quantify “simple”), but with some error analysis, we might be able to see what sentences neural models are misidentifying vs. what sentences combinatorial models are misidentifying.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Build at least one state-of-the-art combinatorial model (adapting from a recent paper). We have two candidate papers: Hirao et al.’s Tree Knapsack approach and Durrett et al.’s Compression/Anaphoricity&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;br /&gt;&lt;h3 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 4pt; margin-top: 16pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 13.999999999999998pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Stretch Goals&lt;/span&gt;&lt;/h3&gt;&lt;ol style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Design our own model that is a combination of the strong points of the combinatorial and neural models. Ideally, our model would be as good as or better than the existing models we implemented on the quantitative and qualitative metrics we use.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Alternatively, we can use ideas from one domain to improve an aspect of a SOTA model in the other domain. For example, we might learn that neural models are great at dealing with named entities, and so incorporate a neural layer in a combinatorial model (perhaps by allowing the output of the neural layer to determine the weights of named entities).&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;li dir=&quot;ltr&quot; style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Design a common system for comparing performance of extractive summarization models. Rather than a differentiable evaluation metric, we think it may be useful to choose a set of “tough” documents to summarize and bundle them together with specific reasons for their difficulty, so that researchers may more easily identify weaknesses in models they are working on.&lt;/span&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h1 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 20pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 20pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Available Resources&lt;/span&gt;&lt;/h1&gt;&lt;h3 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 4pt; margin-top: 16pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 13.999999999999998pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Dataset/Evaluation&lt;/span&gt;&lt;/h3&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;For this problem, we will be using the DailyMail/CNN dataset. From our initial research, this seems to be the standard dataset for both document summarization as well as basic reading comprehension. The dataset has 400,000 articles, and includes both the full text of the article as well as bullet point “highlights”. For reading comprehension, an important word is omitted from the highlights and the machine is asked to fill in the blank. For text summarization, the bullet points are considered the “gold standard” summaries -- machine generated summaries are evaluated against the bullet points, typically&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;using ROUGE metrics&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt; &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;(Lin, 2004). While this works fine for abstractive summarization, this training corpus is not annotated enough for extractive summarization. More specifically, extractive summarization requires sentence level binary annotations, to indicate whether each sentence does or doesn’t belong in the summary. So we need to first convert the bullet points into more fine grained annotations.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;We’ve looked at two papers which briefly touched on this. Nallapati et. al. used a greedy approach, where they added one sentence at a time to the extractive summary while seeking to maximize the Rouge score with respect to the abstractive summary (the bullet points). They also tried to use an RNN decoder in combination with the abstractive summaries to train the extractive model without using sentence-level annotations. However, this approach was slightly less successful than estimating sentence-level annotations. Cheng and Lapata used a different approach - they created a “rule-based system that determines whether a given sentence matches a highlight...The rules take into account the position of the sentence in the document, the unigram and bigram overlap between document sentences and highlights, [and] the number of entities appearing in the highlight and in the document sentence”. It’s not 100% clear what rules the authors used, but according to Nallapati et. al., the rule-based approach found a better “ground-truth” than the greedy approach.&lt;/span&gt;&lt;/div&gt;&lt;h3 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 4pt; margin-top: 16pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 13.999999999999998pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;GitHub Repositories&lt;/span&gt;&lt;/h3&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Some researchers publish the code they used in their paper on GitHub. We can use repos for quick comparisons or to see how they design their code.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;a href=&quot;https://github.com/abisee/pointer-generator&quot; style=&quot;text-decoration: none;&quot;&gt;&lt;span&gt;https://github.com/abisee/pointer-generator&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;: This repo is for See et al.’s Pointer-Generator neural model.&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;a href=&quot;https://github.com/cheng6076/NeuralSum&quot; style=&quot;text-decoration: none;&quot;&gt;&lt;span&gt;https://github.com/cheng6076/NeuralSum&lt;/span&gt;&lt;/a&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;: This repo is for Cheng and Lapata’s neural model, that combines a sentence level RNN with a word level CNN.&lt;/span&gt;&lt;/div&gt;&lt;h1 dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 6pt; margin-top: 20pt;&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 20pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Related Work and References&lt;/span&gt;&lt;/h1&gt;&lt;br /&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Cheng, J., &amp;amp; Lapata, M. (2016). Neural Summarization by Extracting Sentences and Words. &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;arXiv:1603.07252 [Cs]&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;. Retrieved from http://arxiv.org/abs/1603.07252&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Durrett, G., Berg-Kirkpatrick, T., &amp;amp; Klein, D. (2016). Learning-Based Single-Document Summarization with Compression and Anaphoricity Constraints. &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;arXiv:1603.08887 [Cs]&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;. Retrieved from http://arxiv.org/abs/1603.08887&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Hirao, T., Yoshida, Y., Nishino, M., Yasuda, N., &amp;amp; Nagata, M. (2013). Single-Document Summarization as a Tree Knapsack Problem. In &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt; (pp. 1515–1520). Seattle, Washington, USA: Association for Computational Linguistics. Retrieved from http://www.aclweb.org/anthology/D13-1158&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Lin, C.-Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. In S. S. Marie-Francine Moens (Ed.), &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Text Summarization Branches Out: Proceedings of the ACL-04 Workshop&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt; (pp. 74–81). Barcelona, Spain: Association for Computational Linguistics.&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;Nallapati, R., Zhai, F., &amp;amp; Zhou, B. (2016). SummaRuNNer: A Recurrent Neural Network based Sequence Model for Extractive Summarization of Documents. &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;arXiv:1611.04230 [Cs]&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;. Retrieved from http://arxiv.org/abs/1611.04230&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot;&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;See, A., Liu, P. J., &amp;amp; Manning, C. D. (2017). Get To The Point: Summarization with Pointer-Generator Networks. &lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: italic; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;arXiv:1704.04368 [Cs]&lt;/span&gt;&lt;span style=&quot;background-color: transparent; color: black; font-family: Arial; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap; white-space: pre;&quot;&gt;. Retrieved from http://arxiv.org/abs/1704.04368&lt;/span&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-11T06:33:00+00:00</dc:date>
	<dc:creator>Ron &amp; Aditya</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-5878905571398539101">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #3 Project Proposal</title>
	<link>https://teamoverfit.blogspot.com/2018/04/3-project-proposal.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;div&gt;&lt;/div&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;br /&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #3: 04/10/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Social Media Predicts Stock Price (StartUp Mode)&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b id=&quot;docs-internal-guid-213a19db-b353-3e4c-1df6-5dd289daeb8b&quot; style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;There are vast amount of new information related to companies listed on the stock market appears instantly, with immediate impact on stock prices. Our project is for monitoring those text on the social media platform and extract the key information that have impact on the stock prices and predict its future.&lt;/span&gt;&lt;br /&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div dir=&quot;ltr&quot; style=&quot;line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;span&gt;Background and Project objectives &lt;/span&gt;&lt;/div&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;a href=&quot;https://www.investopedia.com/terms/s/stockmarket.asp&quot;&gt;Stock Market&lt;/a&gt; refers to the collection of markets and exchanges where the issuing and trading of equities, bonds and other sorts of securities takes place.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Social media, such as Twitter, often reflects how people think about a company and therefore can be used as an indicator of the changes of stock price in the near future.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Traditionally, analytics use statistical model built on past stock prices and recent news to forecast stock prices. We would like apply Machine Learning and Natural Language Processing models on social media to see if it has enough information for us to make good prediction of future stock price.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;/ul&gt;&lt;div&gt;&lt;span&gt;&lt;span&gt;&lt;b style=&quot;font-weight: normal;&quot;&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt;&lt;span&gt;&lt;b&gt;Proposed methodologies&lt;/b&gt;&lt;span style=&quot;white-space: pre;&quot;&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;b&gt;&lt;span&gt;Dataset:&lt;/span&gt;&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;background-color: white; color: black; vertical-align: baseline; white-space: pre;&quot;&gt;Twitter data: &lt;/span&gt;&lt;span style=&quot;background-color: white; color: #1155cc; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;a href=&quot;https://developer.twitter.com/en/docs&quot;&gt;https://developer.twitter.com/en/docs&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Preprocess twitter data:&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Tokenization&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Stemming&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;Lemmatization&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;background-color: white; color: black; vertical-align: baseline; white-space: pre;&quot;&gt;Bloomberg financial news dataset: &lt;/span&gt;&lt;span style=&quot;background-color: white; color: #1155cc; vertical-align: baseline; white-space: pre;&quot;&gt;&lt;a href=&quot;https://github.com/philipperemy/financial-news-dataset&quot;&gt;https://github.com/philipperemy/financial-news-dataset&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;span&gt;&lt;b&gt;Minimal viable action plan&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;Forecast companies’ stock price changes (UP, DOWN, STAY) &lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;b&gt;&lt;span&gt;Model&lt;/span&gt;&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;N-gram with appropriate smoothing as baseline&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;Use RNN/LSTM/GRU as model&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;&lt;span&gt;User Interface&lt;/span&gt;&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;Command line REPL&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;span&gt;&lt;b&gt;Stretch goals&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;We could implement LSTM/GRU model to extract important information from the text in the preprocess&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;Forecast the approximate future stock price for a company given a future date&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;Auto trader bot that can take streaming tweets from twitter api and update the model prediction &lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;Fusion with 8-K reports to elevate the accuracy&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;span&gt;&lt;b&gt;Evaluation plan&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;F-1 score for (UP/DOWN)&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Loss functions for comparing predictions and expectations.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;Evaluate on time required to do a prediction.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;span&gt;&lt;b style=&quot;white-space: pre;&quot;&gt;Reference&lt;/b&gt;&lt;/span&gt;&lt;br /&gt;&lt;ul style=&quot;margin-bottom: 0pt; margin-top: 0pt;&quot;&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;background-color: white; color: black; vertical-align: baseline; white-space: pre;&quot;&gt;On the Importance of Text Analysis for Stock Price Prediction: &lt;/span&gt;&lt;a href=&quot;https://nlp.stanford.edu/pubs/lrec2014-stock.pdf&quot;&gt;&lt;span style=&quot;background-color: white; color: #1155cc; vertical-align: baseline; white-space: pre;&quot;&gt;https://nlp.stanford.edu/pubs/lrec2014-stock.pdf&lt;/span&gt;&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;color: black; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Stock Trend Prediction Using News Sentiment Analysis: &lt;/span&gt;&lt;span style=&quot;color: #1155cc; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.01958.pdf&quot;&gt;https://arxiv.org/pdf/1607.01958.pdf&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div style=&quot;font-family: times;&quot;&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-11T06:10:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/96fb908765f5">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 02: Getting Started</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-02-getting-started-96fb908765f5?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;&lt;a href=&quot;https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5&quot;&gt;previous post&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Alright, it’s been only 2 days since my last entry, so this will be a relatively short post. The direction I proposed in &lt;strong&gt;Option 1 &lt;/strong&gt;of that post was towards a more robust, interpretable, and informative visualization of attention, particularly in the context of text summarization. A quick recap:&lt;/p&gt;&lt;blockquote&gt;Perhaps interaction can be used to create a more insightful and interpretable visualization framework for understanding attention. For example, text heat-maps are already used widely to visualize sentiment analysis.&lt;/blockquote&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*lsgeuBXGGBog4YkuQNgJVw.png&quot; /&gt;Lin et al. (2017) [6]. Visualization of sentiment analysis on a token-by-token basis.&lt;/figure&gt;&lt;blockquote&gt;In a static context, using this method for attention would require repeat of the same input sequence for each word in the output sequence. Using interaction, however, a model creator could brush over single or sequences of words in the output sequence to view corresponding soft-alignment in the input sequence. Aggregate visualizations could be shown to supplement this view (either aggregates over a particular input / output sequence, or aggregates over all input / output sequences).&lt;/blockquote&gt;&lt;p&gt;I’m currently working on laying out the groundwork for such a project. Task 1: implement a model. Without one, there’s no data to visualize!&lt;/p&gt;&lt;p&gt;With that in mind, here’s what I’ve been up to:&lt;/p&gt;&lt;h4&gt;Finding a Text Summarization Dataset&lt;/h4&gt;&lt;p&gt;A quick survey of recent research papers [1–5] on text summarization points, as well as online forums, points to three commonly used datasets.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://cs.nyu.edu/~kcho/DMQA/&quot;&gt;CNN/Daily Mail Corpus&lt;/a&gt;. A collection of articles and their bullet point summaries, with each bullet split for Q/A purposes. &lt;a href=&quot;https://github.com/abisee/cnn-dailymail&quot;&gt;A script&lt;/a&gt; [1] can be ran over the original dataset to restore the original bullet point summaries, to be used as a summarization corpus.&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www-nlpir.nist.gov/projects/duc/data.html&quot;&gt;DUC Corpus&lt;/a&gt;. In particular, DUC 2003 and DUC 2004. These contain a collection of documents, each accompanied by a short (~10 word) summary. There is also a longer summary for each cluster of documents.&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://catalog.ldc.upenn.edu/ldc2003t05&quot;&gt;Gigaword Corpus&lt;/a&gt;. An annotated collection of millions of documents. The summarization task here would be to predict the headline of each [5]&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The accessibility of the &lt;strong&gt;CNN/Daily Mail Corpus&lt;/strong&gt; (a process is required for the other two), in addition to the prevalence of projects that used it as a primary dataset [1, 2, 4], made it the most attractive option. The relatively longer summaries (~4 bullet points as opposed a short blurb in the other two datasets) also lends itself conveniently to the case of an interactive visualization with multi-token selection (e.g. select a whole bullet point and see where it attended). For a baseline, this will be my dataset!&lt;/p&gt;&lt;h4&gt;Identifying a Baseline Model&lt;/h4&gt;&lt;p&gt;See et al. (2017) [1] lay out a seq2seq attentional model as their baseline (a bidirectional LSTM). I’ll be using this as a baseline model with which to obtain data.&lt;/p&gt;&lt;h4&gt;Getting Some Code Up&lt;/h4&gt;&lt;p&gt;I’ll be using &lt;a href=&quot;http://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt; and the &lt;a href=&quot;http://allennlp.org/&quot;&gt;AllenNLP&lt;/a&gt; toolkit [7] to implement my NN models. These are both ready to go on both my machine and Azure. I’m currently in the process of writing a DatasetReader for the dataset described above.&lt;/p&gt;&lt;h3&gt;Next Steps&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Finish writing the DatasetReader for the CNN/Daily Mail Corpus.&lt;/li&gt;&lt;li&gt;Begin work on a baseline seq2seq attentional model, as described in &lt;strong&gt;Identifying a Baseline Model&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Works Cited&lt;/h4&gt;&lt;p&gt;[1] &lt;a href=&quot;https://arxiv.org/pdf/1704.04368.pdf&quot;&gt;See, Abigail et al. “Get To The Point: Summarization with Pointer-Generator Networks.” &lt;em&gt;ACL&lt;/em&gt; (2017).&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href=&quot;https://arxiv.org/pdf/1712.06100.pdf&quot;&gt;Hasselqvist, Johan et al. “Query-Based Abstractive Summarization Using Neural Networks.” &lt;em&gt;CoRR&lt;/em&gt; abs/1712.06100 (2017): n. pag.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href=&quot;https://arxiv.org/pdf/1602.06023.pdf&quot;&gt;Nallapati, Ramesh et al. “Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.” &lt;em&gt;CoNLL&lt;/em&gt; (2016).&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href=&quot;https://arxiv.org/pdf/1705.04304.pdf&quot;&gt;Paulus, Romain et al. “A Deep Reinforced Model for Abstractive Summarization.” &lt;em&gt;CoRR&lt;/em&gt; abs/1705.04304 (2017): n. pag.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href=&quot;https://arxiv.org/pdf/1509.00685.pdf&quot;&gt;Rush, Alexander M. et al. “A Neural Attention Model for Abstractive Sentence Summarization.” &lt;em&gt;EMNLP&lt;/em&gt; (2015).&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[6] &lt;a href=&quot;https://arxiv.org/pdf/1703.03130.pdf&quot;&gt;Lin, Zhouhan, &lt;em&gt;et al.&lt;/em&gt;, “A structured self-attentive sentence embedding.”&lt;em&gt;arXiv preprint arXiv:1703.03130&lt;/em&gt; (2017).&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[7] &lt;a href=&quot;https://pdfs.semanticscholar.org/a550/2187140cdd98d76ae711973dbcdaf1fef46d.pdf?_ga=2.150901366.1370831839.1522970228-1363309632.1522194596&quot;&gt;Gardner, Matt et al. “AllenNLP: A Deep Semantic Natural Language Processing Platform.” (2017).&lt;/a&gt;&lt;/p&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=96fb908765f5&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-04-06T06:53:32+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-3753031463594823927.post-2253300890173394060">
	<title>Ron Fan, Aditya Saraf &lt;br/&gt; Team PrimeapeNLP: Blog Post #2</title>
	<link>https://cse481n.blogspot.com/2018/04/blog-post-2.html</link>
	<content:encoded>&lt;div&gt;We’ve mostly settled on working on a single document summarization task. We want to pick a type of document to work on summarizing, although we haven’t decided on one specific category yet. &lt;/div&gt;&lt;br /&gt; &lt;div&gt;While we narrow down the details of the project, we have been reading a number of papers and other resources to become more familiar with the subject. We have setup PyTorch on our machines, which we are both familiar with, as well as Tensorflow, which we are still playing around with. We’ve found some interesting repositories on GitHub related to SDS that we are trying out: &lt;/div&gt; &lt;br /&gt; &lt;div&gt;&lt;a href=&quot;https://cse481n.blogspot.com/feeds/posts/default?alt=rss&quot;&gt;https://github.com/tensorflow/models/tree/master/research/textsum&lt;/a&gt;&lt;br /&gt; &lt;a href=&quot;https://cse481n.blogspot.com/feeds/posts/default?alt=rss&quot;&gt;https://github.com/gregdurrett/berkeley-doc-summarizer&lt;/a&gt;&lt;br /&gt; &lt;a href=&quot;https://cse481n.blogspot.com/feeds/posts/default?alt=rss&quot;&gt;https://github.com/chakki-works/sumeval&lt;/a&gt;&lt;br /&gt; &lt;a href=&quot;https://cse481n.blogspot.com/feeds/posts/default?alt=rss&quot;&gt;https://github.com/ceteri/pytextrank&lt;/a&gt;&lt;br /&gt; &lt;a href=&quot;https://cse481n.blogspot.com/feeds/posts/default?alt=rss&quot;&gt;https://github.com/adamfabish/Reduction&lt;/a&gt;&lt;br /&gt;&lt;/div&gt; &lt;br /&gt;&lt;div&gt;Not all of these tools use machine learning - many seem to be heuristic-based sentence extractors. Nonetheless, it is interesting to consider their ideas in the context of neural network approaches. &lt;/div&gt;&lt;br /&gt; &lt;div&gt;One of the reasons we chose to attack this problem is that there is a rich literature to consult; this problem has been worked on in one form or another since 1958 [1]. As one would imagine, this means that there have been many different approaches to this problem, to varying degrees of success. But unlike other problems, where all current approaches are based on deep learning, there is active research into non-neural solutions to SDS. &lt;/div&gt;&lt;br /&gt; &lt;div&gt;Many researchers have tried to solve SDS with combinatorial optimization, reducing it to the Knapsack problem, the Maximum Coverage problem, or the Budgeted Median problem. For example, the Maximum Coverage problem is: given a number k and a collection S, of m sets, choose less than k sets in S that maximize the number of covered elements. To frame SDS as a Maximum Coverage problem, you break the document into “conceptual units”. Conceptual units are supposed to represent a single concept - for example, “the man bought a book” and the “the man read a book”. But it’s not clear at what granularity these conceptual units should be defined. One easy (but not especially effective) solution is to simply make each word a conceptual unit. Then, the document = S, and each sentence is a set of words inside S. The problem is now to pick k sentences from the document that maximize the word coverage in the document [2]. &lt;/div&gt;&lt;br /&gt; &lt;div&gt;One example of a recent non-neural approach is from a paper published 5 years ago [3]. The paper solves SDS by reducing it to the so-called Tree Knapsack Problem. We’ve haven’t fully wrapped our heads around the Tree Knapsack problem (it’s actually not that easy to quickly state), but the researchers’ basically involved representing a document as a Rhetorical Structure Theory-based discourse tree (RST-DT) by “select[ing] textual units according to a preference ranking”. The researchers’ first transform the RST-DT into a dependency-based discourse tree (DEP-DT) in order to get a tree that contains textual units on all nodes (RST-DT only have textual units as leaves), and then trim the DEP-DT using the Tree Knapsack problem.  &lt;/div&gt;&lt;br /&gt; &lt;div&gt;We aim to find a suitable corpus, and implement multiple models directly from these papers as our baseline models. Hopefully, that will give us insight that’ll help us formulate the problem differently. We also want to explore some neural architectures for single document summarization.  &lt;/div&gt;&lt;br /&gt; &lt;div&gt;We also have to consider whether we want to build an extractive or abstractive text summarization - the former collects a set of sentences or phrases that summarize the document while the latter tries to “learn the internal language representation to generate more human-like summaries, paraphrasing the intent of the original text” [4]. We’re leaning towards an extractive model, although we may try both. &lt;/div&gt;&lt;br /&gt; &lt;div&gt;[1] = &lt;a target=&quot;&quot;&gt;https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781119004752.ch3&lt;/a&gt; &lt;br /&gt;[2] = &lt;a target=&quot;&quot;&gt;http://www.anthology.aclweb.org/E/E09/E09-1089.pdf&lt;/a&gt; &lt;br /&gt; [3] = &lt;a target=&quot;&quot;&gt;https://www.semanticscholar.org/paper/Single-Document-Summarization-as-a-Tree-Knapsack-Hirao-Yoshida/ed0c8a7ab911cdb30b7e95edada3a55c01eb22c5&lt;/a&gt;&lt;br /&gt; [4] = &lt;a target=&quot;&quot;&gt;https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/&lt;/a&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-06T06:31:00+00:00</dc:date>
	<dc:creator>Ron &amp; Aditya</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-34377626932024049">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #2 Milestone: Warm up</title>
	<link>https://teamoverfit.blogspot.com/2018/04/2-milestone-warm-up.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;br /&gt;&lt;div&gt;&lt;/div&gt;&lt;br /&gt;&lt;div style=&quot;text-align: start; text-indent: 0px;&quot;&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;Blog Post: #2: 04/05/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div style=&quot;margin: 0px;&quot;&gt;&lt;/div&gt;&lt;br /&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;We first installed Pytorch 3.6 and we tried to run small programs on our local machines.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;We then explored the usage of the RNN and seq2seq APIs, which we are going to use for most of our projects ideas.&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;We looked through the tutorial of RNNs/LSTMs/GRUs from the previous 447 class.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;span id=&quot;docs-internal-guid-97b5af9d-9943-133b-4f16-5d4414eefd5d&quot;&gt;&lt;span&gt;&lt;a href=&quot;https://colab.research.google.com/drive/11iLtGFDpnIuHj5B0rQDGG5lqq6BQ8FRh&quot;&gt;https://colab.research.google.com/drive/11iLtGFDpnIuHj5B0rQDGG5lqq6BQ8FRh&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;We tried to set up an Azure instance for GPU computation&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;We installed cuda support for the Pytorch package and it ran successfully with Tesla K80&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;We revisited the Recurrent Neural Networks, Attention and Reading Comprehension projects from the last quarter and experimented with other Pytorch features related to our project.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-06T04:48:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="https://medium.com/p/ee873b6885d5">
	<title>Halden Lin &lt;br/&gt; Team undef.: NLP Capstone | 01: Options</title>
	<link>https://medium.com/@halden.lin/nlp-capstone-01-options-ee873b6885d5?source=rss-2759d54493c0------2</link>
	<content:encoded>&lt;p&gt;Hello! This post is the first in a series that will document my progression through CSE 481n, taught by Prof. Yejin Choi at the University of Washington.&lt;/p&gt;&lt;p&gt;My github for this project can be found at: &lt;a href=&quot;https://github.com/haldenl/nlpcapstone&quot;&gt;https://github.com/haldenl/nlpcapstone&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;What I hope to explore&lt;/h3&gt;&lt;p&gt;Over the course of the next 10 weeks, I intend to explore the intersection of V&lt;strong&gt;isualization (Vis) and Natural Language Processing (NLP)&lt;/strong&gt;. I am particularly excited to explore the avenues through which Vis can be used to augment the interpretability of Neural Networks (NNs). I’ve spent the past year working around Vis (through classes and research) and am excited to bring what I’ve learned to problems in NLP. I intend to take a &lt;strong&gt;research oriented approach&lt;/strong&gt; to this project.&lt;/p&gt;&lt;h3&gt;Relevant Work (a brief and incomplete list)&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02078.pdf&quot;&gt;Visualizing and Understanding Recurrent Neural Networks, Karpathy et al. (2015)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://www.aclweb.org/anthology/N16-1082&quot;&gt;Visualizing and Understanding Neural Networks in NLP, Li et al. (2016)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://distill.pub/2018/building-blocks/&quot;&gt;The Building Blocks of Interpretability, Olah et al. (2017)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.08220.pdf&quot;&gt;Understanding Neural Networks through Representation Erasure, Li et al. (2017)&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://ufal.mff.cuni.cz/pbml/109/art-rikters-fishel-bojar.pdf&quot;&gt;Visualizing Neural Machine Translation Attention and Confidence, Rikters et al. (2017)&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Directions for Exploration&lt;/h3&gt;&lt;h4&gt;Option 1: Attention&lt;/h4&gt;&lt;p&gt;Visualizing and understanding &lt;strong&gt;attention&lt;/strong&gt;, with a focus on its role in text summarization.&lt;/p&gt;&lt;p&gt;This is my most realized idea at this time, so I will spend more time here explaining my thoughts.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Visualizations of attention are often used in an effort to understand, and subsequently improve, decisions made by neural networks. To my knowledge, the most common way of visualization attention in seq2seq models is via a 2-dimensional heat-map, wherein the attention each decoding unit gives to each input token can be seen.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/612/1*KvfXxucogv8flZHndSJvHg.png&quot; /&gt;Rikters et al. (2017). An attention visualization for a seq2seq problem (in this case, translation). Whiter cells represent higher attention.&lt;/figure&gt;&lt;p&gt;There are a few issues with this format: (1) it is difficult to fit the words (as seen above) on the x-axis, harming readability; (2) this does not scale well with large input or output (e.g. summarization); and (3) we do not read single-tokens at a time (i.e. y-axis), and input and output are generally not in this format either.&lt;/p&gt;&lt;p&gt;As a whole, this format, while simple, is lacking in interpretability. The cognitive work-load of a viewer is less than optimal.&lt;/p&gt;&lt;p&gt;Alternatives can be found in literature, such as the following from Rikters et al. (2017).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*jtRrxf5pIB-OCBsoqUjgJQ.png&quot; /&gt;Rikters et al. (2017). The input sequence is seen on top — output on bottom. Thicker lines denote higher attention.&lt;/figure&gt;&lt;p&gt;However, this also suffers from similar interpretability and scalability issues. Moreover, the thickness of lines as an encoding scheme does not lend itself easily to comparison between words.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Proposed Exploration:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Perhaps interaction can be used to create a more insightful and interpretable visualization framework for understanding attention. For example, text heat-maps are already used widely to visualize sentiment analysis.&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*lsgeuBXGGBog4YkuQNgJVw.png&quot; /&gt;Lin et al. (2017). Visualization of sentiment analysis on a token-by-token basis.&lt;/figure&gt;&lt;p&gt;In a static context, using this method for attention would require repeat of the same input sequence for each word in the output sequence. Using interaction, however, a model creator could brush over single or sequences of words in the output sequence to view corresponding soft-alignment in the input sequence. Aggregate visualizations could be shown to supplement this view (either aggregates over a particular input / output sequence, or aggregates over all input / output sequences).&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Baseline: &lt;/strong&gt;A user-interface for an interactive visualization of attention for seq2seq models (e.g. text summarization models). Exploration of how this visualization method can be used to either improve an existing models or understand the differences between models. This would, of course, require building a model from which to obtain data.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Reach: &lt;/strong&gt;Integration into an existing platform, e.g. in PyTorch to be viewable in TensorBoard.&lt;/p&gt;&lt;h4&gt;Option 2: Neural Network Cells&lt;/h4&gt;&lt;p&gt;Visualizing and understanding the role of cells in a neural network. In particular, the meaning of each cell within a model.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Though more exploration of relevant work will be required if this becomes the path of choice, Kaparthy et al. (2015) present work that serves as the basis for this idea. They show that the role of cells in a neural network can be interpreted by viewing their activations at each point in a given passage. For example, they found in their model a cell that fired at the end of a line (top left).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/1024/1*6yoF78PlE5ETNc9-kbya6w.png&quot; /&gt;Kaparthy et al. (2015). Different cells fire in different contexts.&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Proposed Exploration:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Perhaps a deeper exploration of the activations of neural network cells could lead to insights for visualizations that may aid the interpretability of neural networks.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Baseline: &lt;/strong&gt;Create a program or UI that generates a visualization (either interactive or static), of the activations of each cell in a neural network. Use this information to posit the meanings of each cell and build further visualizations as needed for exploration. This would require building a model from which to obtain observations.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Reach:&lt;/strong&gt; This is a little loose, as it is unclear how much exploration will be needed to produce results. Perhaps as in Option 1, integration of whatever tool created into an existing framework.&lt;/p&gt;&lt;h4&gt;Option 3: Gates and Value flow in RNN models.&lt;/h4&gt;&lt;p&gt;Visualizing and understanding the flow of values through gates in a Recurrent Neural Network (RNN). In particular, allowing for interpretability of gates and the ‘memory’ of cells.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;My motivation for this idea is largely anecdotal. I recall while taking the undergraduate NLP course that the concepts of ‘gates’ and ‘memory’ in RNN models (e.g. GRU, LSTM) were difficult for me to wrap my head around. We have these giant networks with variable length ‘memory’ determined by gates that preform well as a result of this mechanism, but how exactly is this mechanism is used, and on what tokens at what points? Kaparthy et al. (2015) present a way of visualizing the ‘memory’ of cells in an LSTM model via plotting of cells and the time spent right or left saturated (right saturated cells remember values for longer periods of time).&lt;/p&gt;&lt;figure&gt;&lt;img alt=&quot;&quot; src=&quot;https://cdn-images-1.medium.com/max/975/1*Qq9KrefGEl7tM4mPxUi99g.png&quot; /&gt;Kaparthy et al. (2015). Visualizing the cells and their time spent right or left saturated.&lt;/figure&gt;&lt;p&gt;Data-flow graphs have already been developed for neural networks (e.g. Wongsuphasawat et al. (2017)). An RNN specific model with a focus on interpretability of gates may be valuable for the NLP community.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Proposed Exploration:&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Perhaps producing visualizations of a network of cells using information similar to above could lead to improvements in interpretability and aid model improvement.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Baseline: &lt;/strong&gt;Create a program or UI to generate a visualization, as described above, of an small RNN models. Use this generate insight into the model’s behavior (e.g. compare between models), and explore further from there.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Reach: &lt;/strong&gt;Support larger-scale networks. Integration into existing frameworks.&lt;/p&gt;&lt;h3&gt;Works Cited&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.02078.pdf&quot;&gt;Karpathy, Andrej, Justin Johnson, and Li Fei-Fei. “Visualizing and understanding recurrent networks.” &lt;em&gt;arXiv preprint arXiv:1506.02078&lt;/em&gt; (2015).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1506.01066.pdf&quot;&gt;Li, Jiwei, &lt;em&gt;et al.&lt;/em&gt; “Visualizing and understanding neural models in NLP.” &lt;em&gt;arXiv preprint arXiv:1506.01066&lt;/em&gt; (2015).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.08220.pdf&quot;&gt;Li, Jiwei, Will Monroe, and Dan Jurafsky. “Understanding neural networks through representation erasure.” &lt;em&gt;arXiv preprint arXiv:1612.08220&lt;/em&gt; (2016).&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://ufal.mff.cuni.cz/pbml/109/art-rikters-fishel-bojar.pdf&quot;&gt;Rikters, Matīss, Mark Fishel, and Ondřej Bojar. “Visualizing neural machine translation attention and confidence.” &lt;em&gt;The Prague Bulletin of Mathematical Linguistics&lt;/em&gt; 109.1 (2017): 39–50.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://idl.cs.washington.edu/files/2018-TensorFlowGraph-VAST.pdf&quot;&gt;K. Wongsuphasawat &lt;em&gt;et al&lt;/em&gt;., “Visualizing Dataflow Graphs of Deep Learning Models in TensorFlow,” in &lt;em&gt;IEEE Transactions on Visualization and Computer Graphics&lt;/em&gt;, vol. 24, no. 1, pp. 1–12, Jan. 2018.&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.03130.pdf&quot;&gt;Lin, Zhouhan, &lt;em&gt;et al.&lt;/em&gt;, “A structured self-attentive sentence embedding.” &lt;em&gt;arXiv preprint arXiv:1703.03130&lt;/em&gt; (2017).&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img height=&quot;1&quot; src=&quot;https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=ee873b6885d5&quot; width=&quot;1&quot; /&gt;</content:encoded>
	<dc:date>2018-04-04T06:43:21+00:00</dc:date>
	<dc:creator>Halden Lin</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-9203775015655831448.post-3003438141513431489">
	<title>Pinyi Wang, Dawei Shen, Xukai Liu &lt;br/&gt; Team Overfit: #1 Initial Project Ideas</title>
	<link>https://teamoverfit.blogspot.com/2018/04/1-initial-project-ideas.html</link>
	<content:encoded>&lt;h2 style=&quot;height: 0px;&quot;&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;Team Overfit&lt;/span&gt;&lt;/h2&gt;&lt;h3&gt;&lt;span style=&quot;color: #999999; font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h3&gt;&lt;span style=&quot;color: #999999; font-family: Arial, Helvetica, sans-serif;&quot;&gt;Project repo: &lt;span style=&quot;font-size: 18.72px;&quot;&gt;&lt;a href=&quot;https://github.com/pinyiw/nlpcapstone-teamoverfit&quot;&gt;https://github.com/pinyiw/nlpcapstone-teamoverfit&lt;/a&gt;&lt;/span&gt;&lt;/span&gt;&lt;/h3&gt;&lt;h4&gt;&lt;span style=&quot;color: #444444; font-family: Arial, Helvetica, sans-serif;&quot;&gt;Team members: Dawei Shen, Pinyi Wang, Xukai Liu&lt;/span&gt;&lt;/h4&gt;&lt;div&gt;&lt;span style=&quot;color: #444444; font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Blog Post: #1: 04/03/2018&lt;/b&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;color: #444444;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;We are likely going to choose the start-up mode and actually build some cool projects! Here's some of our initial project ideas:&lt;/span&gt;&lt;/div&gt;&lt;div&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Twitter Hate Speech Detection&lt;/b&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Dataset:&lt;/b&gt; &lt;a href=&quot;https://github.com/zeerakw/hatespeech&quot;&gt;https://github.com/zeerakw/hatespeech&lt;/a&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;This dataset contains the tweets ID that are labelled as either Raicist, Sexist or Neither Racist or Sexist.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Minimal viable plan:&lt;/b&gt; We could use LSTM sequence to vector encoding to extract critical features of the tweets. Then, we use RNN and attention mechanism to output the label of the speech and the hate score of tweets in each category.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Stretch goals:&lt;/b&gt; &lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;We could experiment with different model configurations to improve the performance of the model.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;We could build a twitter bot that can collect reports or hateful speech from user, which can be used to train on, so that the model can adapt the model to the latest slangs.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Virtual Date chat bot&lt;/b&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Description: &lt;/b&gt;&lt;/span&gt;&lt;span id=&quot;docs-internal-guid-6febb8b7-8f58-f3ab-f461-d5c0a5077f07&quot;&gt;&lt;span style=&quot;font-family: Arial; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;Use conversations between couples to train a chat bot that user can flirt with when they feel lonely.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;font-family: Arial; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-6febb8b7-8f59-3e54-c748-e595571ddaaa&quot;&gt;&lt;span style=&quot;font-weight: 700; vertical-align: baseline;&quot;&gt;Minimal viable plan:&lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt; Use neural machine translation and attention mechanism to train a generative chat bot. Some training data can be obtained from romantic movies’ dialogue or from Twitter. The challenge would be how to use NLP to classify whether a conversation is flirt or not.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;font-family: Arial; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;span id=&quot;docs-internal-guid-6febb8b7-8f5a-50ce-dc63-78e864ac8b2e&quot;&gt;&lt;span style=&quot;font-weight: 700; vertical-align: baseline;&quot;&gt;Stretch goals:&lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt; Train the chat bot so that it has consistent personality and have long term memory of chat history.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;span style=&quot;font-family: Arial;&quot;&gt;&lt;span style=&quot;white-space: pre-wrap;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/span&gt;&lt;ul&gt;&lt;li&gt;&lt;span id=&quot;docs-internal-guid-6febb8b7-8f5a-cf38-76f0-a21179c20dde&quot;&gt;&lt;span style=&quot;font-family: Arial; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;b&gt;Detect Violations of Laws (Virtual Lawyer)&lt;/b&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;font-family: Arial; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;b&gt;Description:&lt;/b&gt; The project is to try with different models and learn to detect the laws broke given the description of behaviors or given the sworn testimonies in the court.&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span&gt;&lt;span style=&quot;font-family: Arial; vertical-align: baseline; white-space: pre-wrap;&quot;&gt;&lt;span id=&quot;docs-internal-guid-6febb8b7-8f5b-2fce-e8fd-4e47759e160c&quot;&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt;&lt;b&gt;Minimal viable plan:&lt;/b&gt; Experiment with LSTM and attention mechanism&lt;/span&gt;&lt;span style=&quot;background-color: white; color: #757575; vertical-align: baseline;&quot;&gt;.&lt;/span&gt;&lt;span style=&quot;vertical-align: baseline;&quot;&gt; Given the testimony, detects whether the law is broken.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;b&gt;Stretch goals:&lt;/b&gt;&lt;/span&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;Given the testimony, detects and return the list of laws have been broken.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;Generate texts to offend the testimony.&lt;/span&gt;&lt;/li&gt;&lt;li&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;Generate texts to defend the testimony.&lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;span style=&quot;font-family: Arial, Helvetica, sans-serif;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-04T06:36:00+00:00</dc:date>
	<dc:creator>Team Overfit</dc:creator>
</item>
<item rdf:about="tag:blogger.com,1999:blog-3753031463594823927.post-6307882466820480344">
	<title>Ron Fan, Aditya Saraf &lt;br/&gt; Team PrimeapeNLP: Blog Post #1</title>
	<link>https://cse481n.blogspot.com/2018/04/blog-post-1.html</link>
	<content:encoded>&lt;div style=&quot;font-family: Verdana; text-align: left;&quot;&gt;    &lt;div&gt;Temporary GitHub URL: &lt;a href=&quot;https://github.com/rococode/primeapeNLP&quot; target=&quot;_blank&quot;&gt;https://github.com/rococode/primeapeNLP&lt;/a&gt;&lt;/div&gt;    &lt;div&gt;We plan to be in “research mode” for this capstone.&lt;/div&gt;    &lt;div style=&quot;font-size: 1.1rem;&quot;&gt;Three possible ideas:&lt;/div&gt;     &lt;div style=&quot;font-size: 1.1rem;&quot;&gt;1. New evaluation methods for text generation models&lt;/div&gt;    &lt;div&gt;There don’t seem to be many good ways to evaluate the output of machine generated text (such as in the problem of creating hotel reviews). We want our models to generate text that’s indistinguishable from human text, but it’s hard to quantify how similar generated text is to human text, so it’s hard to see when progress is being made. However, it feels like the problem of actually generating human-like text should be harder than the problem of just checking if that text seems human. As a baseline approach, we would like to explore building a regression model for the “humanness” of a piece of unfamiliar text.&lt;/div&gt;    &lt;div&gt;&lt;strong&gt;        M&lt;span style=&quot;font-size: 0.7rem; font-weight: normal;&quot;&gt;(inimal)&lt;/span&gt;        V&lt;span style=&quot;font-size: 0.7rem; font-weight: normal;&quot;&gt;(iable)&lt;/span&gt;        P&lt;span style=&quot;font-size: 0.7rem; font-weight: normal;&quot;&gt;(lan)&lt;/span&gt;    :&lt;/strong&gt;&lt;/div&gt;    &lt;ol&gt;        &lt;li&gt;Build a reasonably large dataset using a combination of web scraping, existing datasets, and existing generative models&lt;/li&gt;        &lt;li&gt;Build a regression model with decent performance on training set&lt;/li&gt;        &lt;li&gt;Build a regression model with decent performance on development and test sets&lt;/li&gt;    &lt;/ol&gt;    &lt;div&gt;&lt;strong&gt;Stretch goals:&lt;/strong&gt;&lt;/div&gt;    &lt;ol&gt;        &lt;li&gt;Use our model to score various generative models and compare our model’s rankings for these generative models to commonly agreed-upon rankings by researchers&lt;/li&gt;        &lt;li&gt;Integrate model scores into a “generate a lot of possibilities, then search for the best one” approach for text generation&lt;/li&gt;    &lt;/ol&gt;    &lt;div&gt;We would also explore non-neural methods for evaluating Natural Language Generation (NLG). One idea would be to compare the probability distribution of generated sentences to real sentences. A common problem is that generated text repeats the most probable sentences over and over. Thus, the distribution of sentences is front-loaded. We hypothesize that generated text with a sentence distribution that closely mirrors real text would be more difficult to distinguish from real text. However, we first need to investigate what real world sentence distributions look like. It may be likely that individual sentences are not likely to repeat - in that case, the distribution would be more-or-less uniform across all sentences. We may need to come up with a novel method to categorize similar sentences. We would have to decide whether to use semantic similarity or syntactic similarity.&lt;/div&gt;    &lt;div&gt;&lt;strong&gt;MVP:&lt;/strong&gt;&lt;/div&gt;    &lt;ol&gt;        &lt;li&gt;Gather a data set - perhaps the data set Ari showed us for hotel reviews.&lt;/li&gt;        &lt;li&gt;Examine the existing probability distribution at the sentence-level in the corpus. If the distribution is too uniform, design a method to place similar sentences in the same “bucket” and re-compute the probability distribution.&lt;/li&gt;        &lt;li&gt;Design metrics to compute the similarity of two distributions; if a model is “good”, the distribution of the generated sentences will match the distribution of the training corpus.&lt;/li&gt;        &lt;li&gt;Use our metric to score generated text models found in the literature.&lt;/li&gt;    &lt;/ol&gt;    &lt;div&gt;&lt;strong&gt;Stretch goals:&lt;/strong&gt;&lt;/div&gt;    &lt;ul&gt;        &lt;li&gt;Use insights from our metrics to improve on current approaches to NLG.&lt;/li&gt;    &lt;/ul&gt;    &lt;div style=&quot;font-size: 1.1rem;&quot;&gt;2. Single-document summarization&lt;/div&gt;    &lt;div&gt;Single document summarization (SDS) models typically label each sentence in the document as in the summary or not in the summary. The problem then becomes a binary classification problem, and many people train a NN with supervised learning. However, there are other non-neural approaches to this problem that have been tried successfully. One paper shows how SDS can be thought of as a tree based Knapsack problem, which is then solved by a Integer Linear Programming (ILP) solver (see: &lt;a href=&quot;https://www.semanticscholar.org/paper/Single-Document-Summarization-as-a-Tree-Knapsack-Hirao-Yoshida/ed0c8a7ab911cdb30b7e95edada3a55c01eb22c5&quot;&gt;https://www.semanticscholar.org/paper/Single-Document-Summarization-as-a-Tree-Knapsack-Hirao-Yoshida/ed0c8a7ab911cdb30b7e95edada3a55c01eb22c5&lt;/a&gt;). We would like to explore both neural models and non-neural approaches to SDS. &lt;/div&gt;    &lt;div&gt;&lt;strong&gt;MVP:&lt;/strong&gt;&lt;/div&gt;    &lt;ol&gt;        &lt;li&gt;As a baseline approach, build neural models from current papers that solve SDS. Evaluate the performance using F1 as well as ROUGE metrics (see: &lt;a href=&quot;https://en.wikipedia.org/wiki/ROUGE_(metric)&quot;&gt;https://en.wikipedia.org/wiki/ROUGE_(metric)&lt;/a&gt;).&lt;/li&gt;        &lt;li&gt;Build neural models from current papers that focus on non-neural approaches, such as the combinatorial approach described above.&lt;/li&gt;        &lt;li&gt;Evaluate neural and non-neural approaches: what do these approaches have in common? What key insights are they leveraging? Are there any generalizations of the problem that can be extracted? Hopefully, this study will allow us to either improve the SOTA neural models or fine tune some non-neural approach.&lt;/li&gt;    &lt;/ol&gt;    &lt;div&gt;&lt;strong&gt;Stretch goal:&lt;/strong&gt;&lt;/div&gt;    &lt;ul&gt;        &lt;li&gt;Use insights from our studies to formulate and solve SDS in a unique way. Evaluate our approach using F1 and ROUGE metrics.&lt;/li&gt;    &lt;/ul&gt;    &lt;div style=&quot;font-size: 1.1rem;&quot;&gt;3. Multi-span comprehension&lt;/div&gt;    &lt;div&gt;Reading comprehension models generally operate by extracting an answer to a question by outputting a start and end index on the original passage. This is not a very human-like way of answering questions, and makes it impossible to generate good answers to some simple factual questions using common sentence structures. We would like to explore ways of answering questions from passages without being limited to a single span from the passage text.&lt;/div&gt;    &lt;div&gt;&lt;strong&gt;MVP:&lt;/strong&gt;&lt;/div&gt;    &lt;ol&gt;        &lt;li&gt;Implement a baseline model that performs near state of the art levels on the SQuAD dataset.&lt;/li&gt;        &lt;li&gt;Build a dataset that requires information from multiple spans to answer the questions well. We will likely create this dataset by hand.&lt;/li&gt;        &lt;li&gt;Build a model that answers questions about a passage by generating multiple spans. We envision designing our model to output a sequence of indices such that every pair of indices corresponds to one part of the answer. This model should perform almost as well as the baseline model on SQuAD, since that’s just a specific case (one span) of a multi-span answer.&lt;/li&gt;        &lt;li&gt;Build upon the previous model by using the output spans to generate a formal answer through a generative model, using the output spans and the question sentence as inputs.&lt;/li&gt;    &lt;/ol&gt;    &lt;div&gt;&lt;strong&gt;Stretch goal:&lt;/strong&gt;&lt;/div&gt;    &lt;ul&gt;        &lt;li&gt;Optimize model to actually be effective at answering multispan questions. We expect this to be quite difficult, so while building a functioning model is part of the MVP, actually having it perform comparatively well is a stretch goal.&lt;/li&gt;    &lt;/ul&gt;&lt;/div&gt;</content:encoded>
	<dc:date>2018-04-02T04:32:00+00:00</dc:date>
	<dc:creator>Ron &amp; Aditya</dc:creator>
</item>

</rdf:RDF>
