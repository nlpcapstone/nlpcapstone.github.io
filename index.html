<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>NLP Capstone Spring 2018</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="planet.css" type="text/css">
<link rel="alternate" href="https://nlpcapstone.github.io/atom.xml" title="" type="application/atom+xml">
</head>

<body>
<h1>NLP Capstone Spring 2018</h1>

<div class="daygroup">
<h2>April 03, 2018</h2>

<div class="channelgroup">







<h3><a href="https://medium.com/@ryanp97?source=rss-6378d85d3a9b------2" title="Stories by Ryan Pham on Medium">Ryan Pham <br/> Team NeuralEmpty</a></h3>


<div class="entrygroup" id="https://medium.com/p/ab3d796c422e">
<h4><a href="https://medium.com/@ryanp97/project-ideas-ab3d796c422e?source=rss-6378d85d3a9b------2">Project Ideas</a></h4>
<div class="entry">
<div class="content">
<p>I plan on following a research track and hope to pursue one of the following ideas:</p><h4><strong>Neural Machine Translation with Semantic Transfer</strong> (as outlined by Jan Buys)</h4><p><em>Minimal Viable Action Plan:</em> <br />1) Use statistical parser (<a href="http://sweaglesw.org/linguistics/ace/">ACE</a>) to get MRS graphs of English/Japanese sentences and convert to DMRS graph (using <a href="https://github.com/delph-in/pydelphin">PyDelphin</a> interface to do parsing and conversion)<br />2) Linearize DMRS graph<br />3) Train a seq2seq that takes linearized English DMRS graph and outputs linearized Japanese DMRS graph</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*J3l_TjWr3A-jOAcrCznqvA.png" />Example of penmen format that DMRS can be represented with (non-linearized). Note that the representation shown is an AMR graph, not a DMRS graph. Figure taken from this <a href="https://arxiv.org/pdf/1704.08381.pdf">paper</a>.</figure><p><em>Stretch Goals:<br /></em>1) Explore different architectures for semantic transfer (e.g. TreeLSTM as opposed to seq2seq)<br />2) Explore ways to learn correspondences between semantic concepts in the two languages</p><h4>DMRS to Text Generation (as outlined by Jan Buys)</h4><p><em>Minimal Viable Action Plan:<br /></em>1) Generate DMRS graph serialization similar to what was outlined above<br />2) Train seq2seq model to generate text directly from graph serialization</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Bndfdhs3ixwG6-JUQPC72A.png" />Example of different graph representations. Figure taken from this <a href="http://www.lrec-conf.org/proceedings/lrec2016/pdf/634_Paper.pdf">paper</a>.</figure><p><em>Stretch Goals:</em><br />1) Experiment with different seq2seq architectures<br />2) Attempt semi-supervised training using a high-precision grammar-based parser</p><h4>Reproduce results / expand on a Paper</h4><p>In this option, I would be attempting to expand on this <a href="https://arxiv.org/pdf/1704.04859.pdf">paper</a> regarding hybrid models. The paper attempts to alleviate and/or solve the issue of out-of-vocabulary words and characters, specifically in Chinese and Japanese. It describes using a CNN in conjunction with an RNN to do so; the CNN learns the radicals of characters and attempts to choose characters with similar radicals since the meaning of radicals remains constant between characters.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/822/1*5GyInYVxc8ifP_YRCHiHHA.png" />Image taken from the linked paper.</figure><p><em>Minimal Viable Action Plan:<br /></em>1) Obtain/create a visual dataset of the characters in order to train the CNN<br />2) Design and explore different methods for joining the two models such as described in the paper<br />3) Train the model end-to-end</p><p><em>Stretch Goals:<br /></em>1) Error analysis on different methods for joining and potential points of error<br />2) Exploration of model variations and architecture (incremental changes similar to this <a href="https://arxiv.org/pdf/1708.04755.pdf">paper</a>)</p><p>For current progress, visit the <a href="https://github.com/ryanp97/NeuralEmpty">repo</a>.</p><img height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ab3d796c422e" width="1" /></div>







<p class="date">
<a href="https://medium.com/@ryanp97/project-ideas-ab3d796c422e?source=rss-6378d85d3a9b------2">by Ryan Pham at April 03, 2018 12:55 AM</a>
</p>
</div>
</div>


</div>

</div>
<div class="daygroup">
<h2>March 30, 2018</h2>

<div class="channelgroup">







<h3><a href="https://nlpcapstonesemparse.blogspot.com/" title="NlpCapstone">Rajas Agashe <br/> Team Han Flying Solo</a></h3>


<div class="entrygroup" id="tag:blogger.com,1999:blog-5600014144802012716.post-6768023392170538237">
<h4><a href="https://nlpcapstonesemparse.blogspot.com/2018/03/blog-post-1.html">Blog Post 1</a></h4>
<div class="entry">
<div class="content">
<div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span style="font-family: arial;"><span style="font-size: 14.6667px; white-space: pre;">I am interested in working in the code generation/semantic parsing space on the research track. My code </span></span><br /><span style="font-family: arial;"><span style="font-size: 14.6667px; white-space: pre;">will be in various branches of my fork of allennlp (https://github.com/rajasagashe/allennlp). I will keep you</span></span><br /><span style="font-family: arial;"><span style="font-size: 14.6667px; white-space: pre;"> updated on which branch/commits I worked on during each blog post. Also note that project idea 1 has </span></span><br /><span style="font-family: arial;"><span style="font-size: 14.6667px; white-space: pre;">the most detail since I have picked it as my project!</span></span></div><h2 dir="ltr" style="line-height: 1.38; margin-bottom: 6pt; margin-top: 18pt;"><span>Project Idea 1</span></h2><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span>Minimum Viable Plan:</span><span> Implement the model in the recent UW paper which introduces the task of </span><br /><span>generating the code for a java function from a natural language description. To further aid code </span><br /><span>generation, the class in which the generated function is to reside is provided, i.e. the class variables </span><br /><span>and methods. Thus the encoder encodes the class as well as the utterance and the decoder uses a </span><br /><span>two step attention mechanism and decodes through the java grammar production rules. </span></div><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span>Stretch Goals:</span><span> Reproduce the state of the art results in the paper. I’m putting this in the stretch goals </span><br /><span>since successfully implementing a neural semantic parser with type constraints is pretty challenging. </span><br /><span>In addition, I hope to experiment with other improvements like encoding the entire class method body</span><br /><span> which wasn’t done.</span></div><h2 dir="ltr" style="line-height: 1.38; margin-bottom: 6pt; margin-top: 18pt;"><span>Project Idea 2</span></h2><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span>Minimum Viable Plan: </span><span>Implement this paper: </span><a href="https://arxiv.org/pdf/1704.01696.pdf" style="text-decoration: none;"><span>https://arxiv.org/pdf/1704.01696.pdf</span></a><span>. The model is </span><br /><span>similar to that of the previous idea, but the datasets are for python and ifttt instead.</span></div><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span>Stretch Goals: </span><span>Improve the paper’s result.</span></div><h2 dir="ltr" style="line-height: 1.38; margin-bottom: 6pt; margin-top: 18pt;"><span>Project Idea 3</span></h2><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span>Minimum Viable Plan: </span><span>Perform transfer learning across several code generation tasks by using the </span><br /><span>same encoder for them all. This technique would be similar to what was used in the Cove paper </span><br /><a href="https://arxiv.org/pdf/1708.00107.pdf" style="text-decoration: none;"><span>https://arxiv.org/pdf/1708.00107.pdf</span></a><span>. </span></div><div dir="ltr" style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;"><span>Stretch Goals: </span><span>Improve the individual paper results with this technique.</span></div><div><span><br /></span></div></div>







<p class="date">
<a href="https://nlpcapstonesemparse.blogspot.com/2018/03/blog-post-1.html">by nlpcapstone (noreply@blogger.com) at March 30, 2018 10:41 PM</a>
</p>
</div>
</div>


</div>

</div>


<div class="sidebar">

<h2>Subscriptions</h2>
<ul>
<li>
<a href="https://nlpcapstonesemparse.blogspot.com/feeds/posts/default?alt=rss" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="https://nlpcapstonesemparse.blogspot.com/" title="NlpCapstone">Rajas Agashe <br/> Team Han Flying Solo</a>
</li>
<li>
<a href="https://medium.com/feed/@ryanp97" title="subscribe"><img src="images/feed-icon-10x10.png" alt="(feed)"></a> <a href="https://medium.com/@ryanp97?source=rss-6378d85d3a9b------2" title="Stories by Ryan Pham on Medium">Ryan Pham <br/> Team NeuralEmpty</a>
</li>
</ul>

<p>
<strong>Last updated:</strong><br>
April 03, 2018 04:00 PM<br>
<em>All times are UTC.</em><br>

<!--
<br>
Powered by:<br>
<a href="http://www.planetplanet.org/"><img src="images/planet.png" width="80" height="15" alt="Planet" border="0"></a>
</p>

<p>
<h2>Planetarium:</h2>
<ul>
<li><a href="http://www.planetapache.org/">Planet Apache</a></li>
<li><a href="http://planet.freedesktop.org/">Planet freedesktop.org</a></li>
<li><a href="http://planet.gnome.org/">Planet GNOME</a></li>
<li><a href="http://planet.debian.net/">Planet Debian</a></li>
<li><a href="http://planet.fedoraproject.org/">Planet Fedora</a></li>
<li><a href="http://planets.sun.com/">Planet Sun</a></li>
<li><a href="http://www.planetplanet.org/">more...</a></li>
</ul>
</p>
!-->
</div>
</body>

</html>
